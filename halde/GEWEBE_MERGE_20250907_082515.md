# Gewebe-Merge

**Zeitpunkt:** 2025-09-07 08:25:15
**Quelle:** `/private/var/mobile/Containers/Data/Application/99D88FA7-793D-42DF-B05F-90CAB1F4353F/Documents/vault-gewebe/weltgewebe-programmierung/weltgewebe-repo`
**Dateien (inkludiert):** 39
**GesamtgrÃ¶ÃŸe:** 99.37 KB

## ğŸ“ Struktur

```
ğŸ“ weltgewebe-repo/
â”œâ”€â”€ ğŸ“ .codex/
    â”œâ”€â”€ ğŸ“„ maintenance.soft.sh (216.00 B)
    â””â”€â”€ ğŸ“„ setup.sh (389.00 B)
â”œâ”€â”€ ğŸ“ .devcontainer/
    â”œâ”€â”€ ğŸ“„ devcontainer.json (523.00 B)
    â”œâ”€â”€ ğŸ“„ Dockerfile (354.00 B)
    â”œâ”€â”€ ğŸ“„ postCreate.sh (1.22 KB)
    â””â”€â”€ ğŸ“„ postStart.sh (515.00 B)
â”œâ”€â”€ ğŸ“ .github/
    â””â”€â”€ ğŸ“ workflows/
        â””â”€â”€ ğŸ“„ ci.yml (3.80 KB)
â”œâ”€â”€ ğŸ“ apps/
    â””â”€â”€ ğŸ“ api-elysia/
        â”œâ”€â”€ ğŸ“ src/
            â”œâ”€â”€ ğŸ“„ metrics.ts (1.86 KB)
            â””â”€â”€ ğŸ“„ server.ts (1.92 KB)
        â”œâ”€â”€ ğŸ“„ package.json (425.00 B)
        â””â”€â”€ ğŸ“„ tsconfig.json (225.00 B)
â”œâ”€â”€ ğŸ“ docs/
    â”œâ”€â”€ ğŸ“„ allerersterStich.md (9.40 KB)
    â”œâ”€â”€ ğŸ“„ fahrplan.md (4.46 KB)
    â”œâ”€â”€ ğŸ“„ inhalt.md (9.47 KB)
    â”œâ”€â”€ ğŸ“„ webstack.md (5.40 KB)
    â”œâ”€â”€ ğŸ“„ wg.md (592.00 B)
    â””â”€â”€ ğŸ“„ zusammenstellung.md (9.83 KB)
â”œâ”€â”€ ğŸ“ packages/
    â”œâ”€â”€ ğŸ“ contracts/
        â”œâ”€â”€ ğŸ“ src/
            â””â”€â”€ ğŸ“„ index.ts (410.00 B)
        â””â”€â”€ ğŸ“„ package.json (172.00 B)
    â””â”€â”€ ğŸ“ core/
        â”œâ”€â”€ ğŸ“ src/
            â””â”€â”€ ğŸ“„ index.ts (134.00 B)
        â””â”€â”€ ğŸ“„ package.json (149.00 B)
â”œâ”€â”€ ğŸ“ scripts/
    â”œâ”€â”€ ğŸ“ k6/
        â””â”€â”€ ğŸ“„ smoke.js (608.00 B)
    â”œâ”€â”€ ğŸ“ lighthouse/
        â”œâ”€â”€ ğŸ“„ budgets.json (218.00 B)
        â””â”€â”€ ğŸ“„ lhci-mobile.sh (607.00 B)
    â””â”€â”€ ğŸ“„ codex-run.sh (1.44 KB)
â”œâ”€â”€ ğŸ“„ .api-dev.log (6.03 KB)
â”œâ”€â”€ ğŸ“„ .git (140.00 B)
â”œâ”€â”€ ğŸ“„ .gitignore (365.00 B)
â”œâ”€â”€ ğŸ“„ bun.lock (11.55 KB)
â”œâ”€â”€ ğŸ“„ e --continue (1.51 KB)
â”œâ”€â”€ ğŸ“„ package.json (800.00 B)
â”œâ”€â”€ ğŸ“„ README.md (142.00 B)
â”œâ”€â”€ ğŸ“„ wg (8.73 KB)
â”œâ”€â”€ ğŸ“„ wg.bak.1757191428 (3.13 KB)
â”œâ”€â”€ ğŸ“„ wg.bak.1757191456 (3.13 KB)
â”œâ”€â”€ ğŸ“„ wg.bak.1757191553 (3.13 KB)
â”œâ”€â”€ ğŸ“„ wg.bak.1757191907 (3.06 KB)
â”œâ”€â”€ ğŸ“„ wg.bak.1757192266 (1.38 KB)
â””â”€â”€ ğŸ“„ wg.bak.1757192687 (2.11 KB)
```

## ğŸ§¾ Manifest

- .api-dev.log | md5=cf4e5686c97261bb15506e010cb619e7 | size=6177
- .codex/maintenance.soft.sh | md5=ad9f75a94c5a14da6a4e6c790e61c409 | size=216
- .codex/setup.sh | md5=bb3b4cad409def84ba20c6f4947e1025 | size=389
- .devcontainer/devcontainer.json | md5=c6d637e1b8d69cf7e77299e57dfd6762 | size=523
- .devcontainer/Dockerfile | md5=95e4572a7fcdce7dd1f57548d91ba614 | size=354
- .devcontainer/postCreate.sh | md5=6c0859d9cadb08392bf19ff316d9388d | size=1250
- .devcontainer/postStart.sh | md5=ef2195a7975e4fa9bd2eb8a96ea69d4d | size=515
- .git | md5=26d46d44c0e820afc45a04275a3ddbf3 | size=140
- .github/workflows/ci.yml | md5=cb5bbad5c5861932af99ad81d18a404a | size=3887
- .gitignore | md5=df44c2a0ced295f8d39f30f696a234aa | size=365
- apps/api-elysia/package.json | md5=41c81d1e0bc972254c03259464580e76 | size=425
- apps/api-elysia/src/metrics.ts | md5=dbfe0f93953eb239a87322d00b9f22ea | size=1907
- apps/api-elysia/src/server.ts | md5=750c49871d9d2c659de657c18dfeba80 | size=1971
- apps/api-elysia/tsconfig.json | md5=66abf84ce7d0d127e8daf9794f9797e9 | size=225
- bun.lock | md5=3e77219550dbe767916ad03a960a1fbd | size=11823
- docs/allerersterStich.md | md5=5dec8c48639fd9184f889b98ad8d130a | size=9629
- docs/fahrplan.md | md5=fda4984fcfb9c3f772b430f3e825aa4d | size=4564
- docs/inhalt.md | md5=7a908b6aac46294b34815d1a1f2fba75 | size=9696
- docs/webstack.md | md5=d022c17c71d32af68781069fab712724 | size=5532
- docs/wg.md | md5=28a912bf6aeb4d1e24b691d142ab325a | size=592
- docs/zusammenstellung.md | md5=6a195cd2a53856173081c518421d6e65 | size=10065
- e --continue | md5=477db6723663d90edf27ee63219bdc0e | size=1545
- package.json | md5=055032b79e56a2a61be0ad6c7feb1599 | size=800
- packages/contracts/package.json | md5=8a9ad7e36891b9e0eb0d4cb61fe35d90 | size=172
- packages/contracts/src/index.ts | md5=9982236363b211367f6d11cf05eaf7b2 | size=410
- packages/core/package.json | md5=3f4638a82ff7c33f9f77116ffa319719 | size=149
- packages/core/src/index.ts | md5=dddafb7b560628f80672d747b2803574 | size=134
- README.md | md5=0e191d4a1abf4c9b9b36c6b8ca286e7b | size=142
- scripts/codex-run.sh | md5=aa405aaf49be3e7cce108a0736d2b4f9 | size=1475
- scripts/k6/smoke.js | md5=af3175daef4e53356b4bf840883587fc | size=608
- scripts/lighthouse/budgets.json | md5=acd2a55266da226446749aa3b0ac91a7 | size=218
- scripts/lighthouse/lhci-mobile.sh | md5=b7622061d0310048c5e635393fc9ffb8 | size=607
- wg | md5=55b1f2c81b3834b7ead6905c78b33405 | size=8942
- wg.bak.1757191428 | md5=d59fb56350419c42b47bcef60f0daa97 | size=3203
- wg.bak.1757191456 | md5=d59fb56350419c42b47bcef60f0daa97 | size=3203
- wg.bak.1757191553 | md5=d59fb56350419c42b47bcef60f0daa97 | size=3203
- wg.bak.1757191907 | md5=9d7aac2bbbe894bd5ca43683baba6244 | size=3129
- wg.bak.1757192266 | md5=8e3d7357e16f24147bc394714a495e42 | size=1409
- wg.bak.1757192687 | md5=36fa6eabbe3555b26d45d499d7b3c627 | size=2160

## ğŸ“„ Dateiinhalte

### ğŸ“„ .api-dev.log

**GrÃ¶ÃŸe:** 6.03 KB

```
Usage: bun run [flags] <file or script>

Flags:
      --silent                        Don't print the script command
      --elide-lines=<val>             Number of lines of script output shown when using --filter (default: 10). Set to 0 to show all lines.
  -F, --filter=<val>                  Run a script in all workspace packages matching the pattern
  -b, --bun                           Force a script or package to use Bun's runtime instead of Node.js (via symlinking node)
      --shell=<val>                   Control the shell used for package.json scripts. Supports either 'bun' or 'system'
      --watch                         Automatically restart the process on file change
      --hot                           Enable auto reload in the Bun runtime, test runner, or bundler
      --no-clear-screen               Disable clearing the terminal screen on reload when --hot or --watch is enabled
      --smol                          Use less memory, but run garbage collection more often
  -r, --preload=<val>                 Import a module before other modules are loaded
      --require=<val>                 Alias of --preload, for Node.js compatibility
      --import=<val>                  Alias of --preload, for Node.js compatibility
      --inspect=<val>                 Activate Bun's debugger
      --inspect-wait=<val>            Activate Bun's debugger, wait for a connection before executing
      --inspect-brk=<val>             Activate Bun's debugger, set breakpoint on first line of code and wait
      --if-present                    Exit without an error if the entrypoint does not exist
      --no-install                    Disable auto install in the Bun runtime
      --install=<val>                 Configure auto-install behavior. One of "auto" (default, auto-installs when no node_modules), "fallback" (missing packages only), "force" (always).
  -i                                  Auto-install dependencies during execution. Equivalent to --install=fallback.
  -e, --eval=<val>                    Evaluate argument as a script
  -p, --print=<val>                   Evaluate argument as a script and print the result
      --prefer-offline                Skip staleness checks for packages in the Bun runtime and resolve from disk
      --prefer-latest                 Use the latest matching versions of packages in the Bun runtime, always checking npm
      --port=<val>                    Set the default port for Bun.serve
      --conditions=<val>              Pass custom conditions to resolve
      --fetch-preconnect=<val>        Preconnect to a URL while code is loading
      --max-http-header-size=<val>    Set the maximum size of HTTP headers in bytes. Default is 16KiB
      --dns-result-order=<val>        Set the default order of DNS lookup results. Valid orders: verbatim (default), ipv4first, ipv6first
      --expose-gc                     Expose gc() on the global object. Has no effect on Bun.gc().
      --no-deprecation                Suppress all reporting of the custom deprecation.
      --throw-deprecation             Determine whether or not deprecation warnings result in errors.
      --title=<val>                   Set the process title
      --zero-fill-buffers             Boolean to force Buffer.allocUnsafe(size) to be zero-filled.
      --redis-preconnect              Preconnect to $REDIS_URL at startup
      --sql-preconnect                Preconnect to PostgreSQL at startup
      --no-addons                     Throw an error if process.dlopen is called, and disable export condition "node-addons"
      --unhandled-rejections=<val>    One of "strict", "throw", "warn", "none", or "warn-with-error-code"
      --console-depth=<val>           Set the default depth for console.log object inspection (default: 2)
      --user-agent=<val>              Set the default User-Agent header for HTTP requests
      --main-fields=<val>             Main fields to lookup in package.json. Defaults to --target dependent
      --preserve-symlinks             Preserve symlinks when resolving files
      --preserve-symlinks-main        Preserve symlinks when resolving the main entry point
      --extension-order=<val>         Defaults to: .tsx,.ts,.jsx,.js,.json
      --tsconfig-override=<val>       Specify custom tsconfig.json. Default <d>$cwd<r>/tsconfig.json
  -d, --define=<val>                  Substitute K:V while parsing, e.g. --define process.env.NODE_ENV:"development". Values are parsed as JSON.
      --drop=<val>                    Remove function calls, e.g. --drop=console removes all console.* calls.
  -l, --loader=<val>                  Parse files with .ext:loader, e.g. --loader .js:jsx. Valid loaders: js, jsx, ts, tsx, json, toml, text, file, wasm, napi
      --no-macros                     Disable macros from being executed in the bundler, transpiler and runtime
      --jsx-factory=<val>             Changes the function called when compiling JSX elements using the classic JSX runtime
      --jsx-fragment=<val>            Changes the function called when compiling JSX fragments
      --jsx-import-source=<val>       Declares the module specifier to be used for importing the jsx and jsxs factory functions. Default: "react"
      --jsx-runtime=<val>             "automatic" (default) or "classic"
      --ignore-dce-annotations        Ignore tree-shaking annotations such as @__PURE__
      --env-file=<val>                Load environment variables from the specified file(s)
      --cwd=<val>                     Absolute path to resolve files & entry points from. This just changes the process' cwd.
  -c, --config=<val>                  Specify path to Bun config file. Default <d>$cwd<r>/bunfig.toml
  -h, --help                          Display this menu and exit

Examples:
  Run a JavaScript or TypeScript file
  bun run ./index.js
  bun run ./index.tsx

  Run a package.json script
  bun run dev
  bun run lint

Full documentation is available at https://bun.com/docs/cli/run

package.json scripts (3 found):
  $ bun run dev
    bun --hot src/server.ts

  $ bun run build
    bun build --target bun src/server.ts --outdir dist

  $ bun run check
    tsc --noEmit

```

### ğŸ“„ .codex/maintenance.soft.sh

**GrÃ¶ÃŸe:** 216.00 B

```bash
#!/usr/bin/env bash
set -euo pipefail
# Leichtes Warmup vor jeder Aufgabe (keine Netzoperationen).
export BUN_INSTALL="$HOME/.bun"
export PATH="$BUN_INSTALL/bin:$PATH"
echo "Codex maintenance: nothing to do (warm)."
```

### ğŸ“„ .codex/setup.sh

**GrÃ¶ÃŸe:** 389.00 B

```bash
#!/usr/bin/env bash
set -euo pipefail

# Bun installieren
if ! command -v bun >/dev/null 2>&1; then
  curl -fsSL https://bun.sh/install | bash
fi
export BUN_INSTALL="$HOME/.bun"
export PATH="$BUN_INSTALL/bin:$PATH"

# Node Tooling aktiv
corepack enable || true

# AbhÃ¤ngigkeiten
bun install --frozen-lockfile || true
bun install -C apps/web || true
bun install -C apps/api-elysia || true
```

### ğŸ“„ .devcontainer/devcontainer.json

**GrÃ¶ÃŸe:** 523.00 B

```json
{
  "name": "weltgewebe â€¢ bun 1.2.21",
  "build": { "dockerfile": "Dockerfile" },
  "remoteUser": "vscode",
  "workspaceFolder": "/workspaces/weltgewebe",
  "forwardPorts": [5173, 8787, 8080],
  "postCreateCommand": "bun install",
  "customizations": {
    "vscode": {
      "settings": {
        "terminal.integrated.defaultProfile.linux": "bash",
        "editor.formatOnSave": true
      },
      "extensions": [
        "oven.bun-vscode",
        "biomejs.biome",
        "dbaeumer.vscode-eslint"
      ]
    }
  }
}
```

### ğŸ“„ .devcontainer/Dockerfile

**GrÃ¶ÃŸe:** 354.00 B

```
FROM oven/bun:1.2.21-debian

# Tools, k6, git, curl etc. (schlank halten)
RUN apt-get update && apt-get install -y --no-install-recommends \
    git ca-certificates curl jq unzip \
 && rm -rf /var/lib/apt/lists/*

# Non-root user (codespace-konform)
ARG USERNAME=vscode
RUN useradd -m -s /bin/bash $USERNAME
USER $USERNAME
WORKDIR /workspaces/weltgewebe
```

### ğŸ“„ .devcontainer/postCreate.sh

**GrÃ¶ÃŸe:** 1.22 KB

```bash
#!/usr/bin/env bash
set -e  # bewusst kein -u/pipefail (Codespaces-tolerant)

echo "[wg] postCreate start"

# Bun-Pfad nur setzen, wenn existiert
if [ -d "$HOME/.bun/bin" ]; then
  export PATH="$HOME/.bun/bin:$PATH"
fi

# Dev-Zert ggf. erzeugen (leise)
mkdir -p .devcert
if [ ! -f .devcert/localhost.key ]; then
  if command -v openssl >/dev/null 2>&1; then
    openssl req -x509 -nodes -newkey rsa:2048 -days 3650 \
      -subj "/CN=localhost" \
      -keyout .devcert/localhost.key -out .devcert/localhost.crt >/dev/null 2>&1 || true
  fi
fi

# Dependencies nur wenn package.json vorhanden
if [ -f package.json ]; then
  if command -v bun >/dev/null 2>&1; then
    bun install --no-progress || true
  else
    echo "[wg] Hinweis: bun noch nicht im PATH â€“ dependencies werden spÃ¤ter installiert."
  fi
fi

# k6-Smoke-Stub (harmlos, idempotent)
mkdir -p scripts/k6
cat > scripts/k6/smoke.js << "EOF"
import http from "k6/http"; import { check } from "k6";
export const options = { vus: 1, iterations: 3 };
export default function () {
  const urls = ["http://localhost:3000/health","http://localhost:3000/metrics"];
  urls.forEach(u => check(http.get(u), { "status 2xx": r => r.status >=200 && r.status<300 }));
}
EOF

echo "[wg] postCreate done"
```

### ğŸ“„ .devcontainer/postStart.sh

**GrÃ¶ÃŸe:** 515.00 B

```bash
#!/usr/bin/env bash
set -e
if [ -d "$HOME/.bun/bin" ]; then
  export PATH="$HOME/.bun/bin:$PATH"
fi

# node_modules â€self-healâ€œ nur versuchen, wenn bun da ist
if [ -d node_modules ] && command -v bun >/dev/null 2>&1; then
  bun install --no-progress || true
fi

echo -e "\n[wg] Devcontainer bereit. Beispiele:"
echo "  bun --version      # Bun prÃ¼fen"
echo "  bun run dev        # SvelteKit (falls vorhanden)"
echo "  bun run api        # Elysia API (falls vorhanden)"
echo "  bunx k6 run scripts/k6/smoke.js"
```

### ğŸ“„ .git

**GrÃ¶ÃŸe:** 140.00 B

```
gitdir: /private/var/mobile/Containers/Shared/AppGroup/7C18D54F-DE15-4549-B28E-92E4AF7801BC/GitFolders/C9CB5654-7FFB-46CF-A9B8-74EF2B60D29D/
```

### ğŸ“„ .github/workflows/ci.yml

**GrÃ¶ÃŸe:** 3.80 KB

```yaml
name: CI

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

permissions:
  contents: read

jobs:
  ci:
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Bun
        uses: oven-sh/setup-bun@v2
        with:
          bun-version: "1.2.21"

      - name: Cache bun install
        uses: actions/cache@v4
        with:
          path: |
            ~/.bun/install/cache
            node_modules
            apps/**/node_modules
            packages/**/node_modules
          key: ${{ runner.os }}-bun-${{ hashFiles(**/bun.lockb) }}
          restore-keys: |
            ${{ runner.os }}-bun-

      - name: Install deps (root + workspaces)
        run: |
          bun install --frozen-lockfile
          [ -f apps/api-elysia/package.json ] && bun install -C apps/api-elysia || true
          [ -f apps/web/package.json ] && bun install -C apps/web || true

      - name: Lint (Biome, falls konfig vorhanden)
        run: |
          if [ -f biome.json ] || [ -f .biome.json ]; then
            bunx @biomejs/biome ci .
          else
            echo "No Biome config found â€“ skipping lint."
          fi

      - name: Typecheck (API)
        run: bun --cwd apps/api-elysia run check

      - name: Unit Tests (bun) + Coverage (Artefakt)
        run: bun test --coverage || (echo "Tests failed"; exit 1)

      - name: Upload Coverage
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage
          path: coverage

      - name: Enforce Coverage >= 80%
        run: |
          set -e
          pct=""
          if [ -f coverage/lcov-report/index.html ]; then
            pct=$(grep -Eo "([0-9]{1,3}\.[0-9]|[0-9]{1,3})%" coverage/lcov-report/index.html | head -n1 | tr -d "%")
          fi
          if [ -z "$pct" ] && [ -f coverage/coverage-summary.json ]; then
            pct=$(node -e "const s=require(./coverage/coverage-summary.json); const t=s.total; const p=t&&t.lines&&t.lines.pct||0; console.log(p)")
          fi
          if [ -z "$pct" ] && [ -f coverage/coverage-final.json ]; then
            pct=$(node -e "
              const data=require(./coverage/coverage-final.json);
              let covered=0,total=0;
              for(const f of Object.values(data)){
                if(!f||!f.s) continue;
                for(const k in f.s){ total++; if(f.s[k]>0) covered++; }
              }
              const p = total? (covered*100/total):0;
              console.log(p.toFixed(2));
            ")
          fi
          if [ -z "$pct" ]; then echo "Coverage nicht ermittelbar â€“ setze 0"; pct=0; fi
          echo "Coverage: ${pct}%"
          awk -v p="$pct" "BEGIN{ if (p+0 < 80) { print \"âŒ Coverage < 80%\"; exit 1 } else { print \"âœ… Coverage OK\" } }"

      - name: Build API
        run: bun --cwd apps/api-elysia run build

      - name: Start API (bg) & wait on /health
        run: |
          bun --cwd apps/api-elysia run dev >/tmp/api.log 2>&1 &
          for i in {1..30}; do
            if curl -fsS http://localhost:8787/health >/dev/null 2>&1; then
              echo "API up"; break
            fi
            sleep 1
          done
          curl -fsS http://localhost:8787/metrics | grep -q "wg_up" || { echo "metrics missing"; exit 1; }

      - name: k6 Smoke (/health,/metrics)
        env:
          API_BASE: http://localhost:8787
        run: bunx --yes k6@0.51.0 run scripts/k6/smoke.js

      - name: Axe (wartet auf apps/web)
        if: ${{ hashFiles(apps/web/package.json) !=  }}
        run: echo "TODO: axe-ci aktivieren, sobald apps/web existiert."

      - name: Stop API (immer)
        if: always()
        run: |
          pkill -f "bun .*apps/api-elysia" || true
          echo "--- API LOG ---"
          tail -n 200 /tmp/api.log || true
```

### ğŸ“„ .gitignore

**GrÃ¶ÃŸe:** 365.00 B

```
# OS / Editor
.DS_Store
Thumbs.db
*.swp
*~
*.log

# Backups / Temp
*.bak
*.tmp
*.temp
*.old
*.orig
*.rej

# Node / JS
node_modules/
.npm/
.pnpm-store/
.yarn/
dist/
.build/
coverage/
.vite/
.svelte-kit/

# Python
__pycache__/
*.py[cod]
.venv/
.uv/

# IDE
.idea/
.vscode/*
!.vscode/extensions.json
!.vscode/settings.json

# Misc
*.tgz
# wg temporÃ¤r
wg.tmp*
wg.bak.*
```

### ğŸ“„ apps/api-elysia/package.json

**GrÃ¶ÃŸe:** 425.00 B

```json
{
  "name": "@welt/api-elysia",
  "version": "0.1.0",
  "type": "module",
  "scripts": {
    "dev": "bun --hot src/server.ts",
    "build": "bun build --target bun src/server.ts --outdir dist",
    "check": "tsc --noEmit"
  },
  "dependencies": {
    "elysia": "^1.3.21",
    "zod": "^3.23.8",
    "@welt/contracts": "workspace:*",
    "@welt/core": "workspace:*"
  },
  "devDependencies": {
    "typescript": "^5.6.2"
  }
}
```

### ğŸ“„ apps/api-elysia/src/metrics.ts

**GrÃ¶ÃŸe:** 1.86 KB

```typescript
type Labels = Record<string,string>;
const now = () => performance.now();

function line(name: string, value: number, labels?: Labels) {
  const lbl = labels && Object.keys(labels).length
    ? "{" + Object.entries(labels).map(([k,v]) => `${k}="${v}"`).join(",") + "}"
    : "";
  return `${name}${lbl} ${value}\n`;
}

export class Metrics {
  requestsTotal: Record<string, number> = {};
  duration: { buckets: number[], counts: Record<string, number[]> } = {
    buckets: [50,100,200,300,500,1000,2000], // ms
    counts: {}
  };
  up = 1;

  incRequest(route: string, method: string, status: number) {
    const key = `${route}|${method}|${status}`;
    this.requestsTotal[key] = (this.requestsTotal[key] ?? 0) + 1;
  }

  observeDuration(route: string, ms: number) {
    const key = route;
    if (!this.duration.counts[key]) this.duration.counts[key] = new Array(this.duration.buckets.length+1).fill(0);
    const idx = this.duration.buckets.findIndex(b => ms <= b);
    const bucketIndex = idx === -1 ? this.duration.buckets.length : idx;
    this.duration.counts[key][bucketIndex] += 1;
  }

  render() {
    let out = "";
    out += line("wg_up", this.up);
    for (const [k,v] of Object.entries(this.requestsTotal)) {
      const [route, method, status] = k.split("|");
      out += line("wg_requests_total", v, {route, method, status});
    }
    // histogram exposition
    for (const [route, arr] of Object.entries(this.duration.counts)) {
      let cum = 0;
      for (let i=0;i<arr.length;i++){
        cum += arr[i];
        const le = i < this.duration.buckets.length ? this.duration.buckets[i] : "+Inf";
        out += line("wg_request_duration_ms_bucket", cum, {route, le: String(le)});
      }
    }
    return out || "wg_up 1\n";
  }

  timer(route: string) {
    const start = now();
    return () => this.observeDuration(route, now()-start);
  }
}
export const metrics = new Metrics();
```

### ğŸ“„ apps/api-elysia/src/server.ts

**GrÃ¶ÃŸe:** 1.92 KB

```typescript
import { Elysia, t } from "elysia";
import { ok, err } from "@welt/core";
import { metrics } from "./metrics";

function reqId(): string {
  return crypto.randomUUID();
}

const app = new Elysia()
  // Request-ID + JSON-Log Middleware
  .onBeforeHandle(({ request, set }) => {
    const id = request.headers.get("x-request-id") || reqId();
    set.headers["x-request-id"] = id;
    (request as any)._rid = id;
  })
  .onAfterHandle(({ request, response, path }) => {
    const id = (request as any)._rid ?? "-";
    const method = request.method;
    const status = (response as any)?.status ?? 200;
    metrics.incRequest(path, method, status);
    console.log(JSON.stringify({
      ts: new Date().toISOString(),
      level: "info",
      request_id: id,
      method, path, status
    }));
  })

  // Health
  .get("/health", () => {
    const stop = metrics.timer("/health");
    stop();
    return { status: "ok", ts: new Date().toISOString() };
  })

  // Metrics (Prometheus-Textformat)
  .get("/metrics", () => metrics.render(), { detail: { type: "text/plain" } })

  // Echo (validiert, simples Beispiel)
  .post("/echo",
    ({ body }) => {
      const stop = metrics.timer("/echo");
      stop();
      return ok({ id: crypto.randomUUID(), message: body.message });
    },
    {
      body: t.Object({ message: t.String({ minLength: 1, maxLength: 200 }) })
    }
  )

  // Fehlerbeispiel (Fehlerformat + correlation_id)
  .get("/boom", () => {
    throw new Error("intentional");
  })
  .onError(({ error, request, set }) => {
    const id = (request as any)._rid ?? reqId();
    set.status = 500;
    console.error(JSON.stringify({
      ts: new Date().toISOString(),
      level: "error",
      request_id: id,
      error: { name: error.name, message: error.message }
    }));
    return err({ code: "INTERNAL_ERROR", message: "unexpected error", correlation_id: id });
  });

app.listen({ port: 8787 });
console.log(`API ready on http://localhost:8787`);
```

### ğŸ“„ apps/api-elysia/tsconfig.json

**GrÃ¶ÃŸe:** 225.00 B

```json
{
  "compilerOptions": {
    "target": "ES2022",
    "module": "ES2022",
    "moduleResolution": "Bundler",
    "strict": true,
    "skipLibCheck": true,
    "types": ["bun"],
    "outDir": "dist"
  },
  "include": ["src"]
}
```

### ğŸ“„ bun.lock

**GrÃ¶ÃŸe:** 11.55 KB

```
{
  "lockfileVersion": 1,
  "workspaces": {
    "": {
      "name": "weltgewebe",
      "devDependencies": {
        "@biomejs/biome": "^1.9.4",
        "concurrently": "^9.0.1",
        "typescript": "^5.6.2",
        "zod": "^3.23.8",
      },
    },
    "apps/api-elysia": {
      "name": "@welt/api-elysia",
      "version": "0.1.0",
      "dependencies": {
        "@welt/contracts": "workspace:*",
        "@welt/core": "workspace:*",
        "elysia": "^1.3.21",
        "zod": "^3.23.8",
      },
      "devDependencies": {
        "typescript": "^5.6.2",
      },
    },
    "packages/contracts": {
      "name": "@welt/contracts",
      "version": "1.0.0",
      "devDependencies": {
        "typescript": "^5.6.2",
        "zod": "^3.23.8",
      },
    },
    "packages/core": {
      "name": "@welt/core",
      "version": "1.0.0",
      "devDependencies": {
        "typescript": "^5.6.2",
      },
    },
  },
  "packages": {
    "@biomejs/biome": ["@biomejs/biome@1.9.4", "", { "optionalDependencies": { "@biomejs/cli-darwin-arm64": "1.9.4", "@biomejs/cli-darwin-x64": "1.9.4", "@biomejs/cli-linux-arm64": "1.9.4", "@biomejs/cli-linux-arm64-musl": "1.9.4", "@biomejs/cli-linux-x64": "1.9.4", "@biomejs/cli-linux-x64-musl": "1.9.4", "@biomejs/cli-win32-arm64": "1.9.4", "@biomejs/cli-win32-x64": "1.9.4" }, "bin": { "biome": "bin/biome" } }, "sha512-1rkd7G70+o9KkTn5KLmDYXihGoTaIGO9PIIN2ZB7UJxFrWw04CZHPYiMRjYsaDvVV7hP1dYNRLxSANLaBFGpog=="],

    "@biomejs/cli-darwin-arm64": ["@biomejs/cli-darwin-arm64@1.9.4", "", { "os": "darwin", "cpu": "arm64" }, "sha512-bFBsPWrNvkdKrNCYeAp+xo2HecOGPAy9WyNyB/jKnnedgzl4W4Hb9ZMzYNbf8dMCGmUdSavlYHiR01QaYR58cw=="],

    "@biomejs/cli-darwin-x64": ["@biomejs/cli-darwin-x64@1.9.4", "", { "os": "darwin", "cpu": "x64" }, "sha512-ngYBh/+bEedqkSevPVhLP4QfVPCpb+4BBe2p7Xs32dBgs7rh9nY2AIYUL6BgLw1JVXV8GlpKmb/hNiuIxfPfZg=="],

    "@biomejs/cli-linux-arm64": ["@biomejs/cli-linux-arm64@1.9.4", "", { "os": "linux", "cpu": "arm64" }, "sha512-fJIW0+LYujdjUgJJuwesP4EjIBl/N/TcOX3IvIHJQNsAqvV2CHIogsmA94BPG6jZATS4Hi+xv4SkBBQSt1N4/g=="],

    "@biomejs/cli-linux-arm64-musl": ["@biomejs/cli-linux-arm64-musl@1.9.4", "", { "os": "linux", "cpu": "arm64" }, "sha512-v665Ct9WCRjGa8+kTr0CzApU0+XXtRgwmzIf1SeKSGAv+2scAlW6JR5PMFo6FzqqZ64Po79cKODKf3/AAmECqA=="],

    "@biomejs/cli-linux-x64": ["@biomejs/cli-linux-x64@1.9.4", "", { "os": "linux", "cpu": "x64" }, "sha512-lRCJv/Vi3Vlwmbd6K+oQ0KhLHMAysN8lXoCI7XeHlxaajk06u7G+UsFSO01NAs5iYuWKmVZjmiOzJ0OJmGsMwg=="],

    "@biomejs/cli-linux-x64-musl": ["@biomejs/cli-linux-x64-musl@1.9.4", "", { "os": "linux", "cpu": "x64" }, "sha512-gEhi/jSBhZ2m6wjV530Yy8+fNqG8PAinM3oV7CyO+6c3CEh16Eizm21uHVsyVBEB6RIM8JHIl6AGYCv6Q6Q9Tg=="],

    "@biomejs/cli-win32-arm64": ["@biomejs/cli-win32-arm64@1.9.4", "", { "os": "win32", "cpu": "arm64" }, "sha512-tlbhLk+WXZmgwoIKwHIHEBZUwxml7bRJgk0X2sPyNR3S93cdRq6XulAZRQJ17FYGGzWne0fgrXBKpl7l4M87Hg=="],

    "@biomejs/cli-win32-x64": ["@biomejs/cli-win32-x64@1.9.4", "", { "os": "win32", "cpu": "x64" }, "sha512-8Y5wMhVIPaWe6jw2H+KlEm4wP/f7EW3810ZLmDlrEEy5KvBsb9ECEfu/kMWD484ijfQ8+nIi0giMgu9g1UAuuA=="],

    "@borewit/text-codec": ["@borewit/text-codec@0.1.1", "", {}, "sha512-5L/uBxmjaCIX5h8Z+uu+kA9BQLkc/Wl06UGR5ajNRxu+/XjonB5i8JpgFMrPj3LXTCPA0pv8yxUvbUi+QthGGA=="],

    "@sinclair/typebox": ["@sinclair/typebox@0.34.41", "", {}, "sha512-6gS8pZzSXdyRHTIqoqSVknxolr1kzfy4/CeDnrzsVz8TTIWUbOBr6gnzOmTYJ3eXQNh4IYHIGi5aIL7sOZ2G/g=="],

    "@tokenizer/inflate": ["@tokenizer/inflate@0.2.7", "", { "dependencies": { "debug": "^4.4.0", "fflate": "^0.8.2", "token-types": "^6.0.0" } }, "sha512-MADQgmZT1eKjp06jpI2yozxaU9uVs4GzzgSL+uEq7bVcJ9V1ZXQkeGNql1fsSI0gMy1vhvNTNbUqrx+pZfJVmg=="],

    "@tokenizer/token": ["@tokenizer/token@0.3.0", "", {}, "sha512-OvjF+z51L3ov0OyAU0duzsYuvO01PH7x4t6DJx+guahgTnBHkhJdG7soQeTSFLWN3efnHyibZ4Z8l2EuWwJN3A=="],

    "@welt/api-elysia": ["@welt/api-elysia@workspace:apps/api-elysia"],

    "@welt/contracts": ["@welt/contracts@workspace:packages/contracts"],

    "@welt/core": ["@welt/core@workspace:packages/core"],

    "ansi-regex": ["ansi-regex@5.0.1", "", {}, "sha512-quJQXlTSUGL2LH9SUXo8VwsY4soanhgo6LNSm84E1LBcE8s3O0wpdiRzyR9z/ZZJMlMWv37qOOb9pdJlMUEKFQ=="],

    "ansi-styles": ["ansi-styles@4.3.0", "", { "dependencies": { "color-convert": "^2.0.1" } }, "sha512-zbB9rCJAT1rbjiVDb2hqKFHNYLxgtk8NURxZ3IZwD3F6NtxbXZQCnnSi1Lkx+IDohdPlFp222wVALIheZJQSEg=="],

    "chalk": ["chalk@4.1.2", "", { "dependencies": { "ansi-styles": "^4.1.0", "supports-color": "^7.1.0" } }, "sha512-oKnbhFyRIXpUuez8iBMmyEa4nbj4IOQyuhc/wy9kY7/WVPcwIO9VA668Pu8RkO7+0G76SLROeyw9CpQ061i4mA=="],

    "cliui": ["cliui@8.0.1", "", { "dependencies": { "string-width": "^4.2.0", "strip-ansi": "^6.0.1", "wrap-ansi": "^7.0.0" } }, "sha512-BSeNnyus75C4//NQ9gQt1/csTXyo/8Sb+afLAkzAptFuMsod9HFokGNudZpi/oQV73hnVK+sR+5PVRMd+Dr7YQ=="],

    "color-convert": ["color-convert@2.0.1", "", { "dependencies": { "color-name": "~1.1.4" } }, "sha512-RRECPsj7iu/xb5oKYcsFHSppFNnsj/52OVTRKb4zP5onXwVF3zVmmToNcOfGC+CRDpfK/U584fMg38ZHCaElKQ=="],

    "color-name": ["color-name@1.1.4", "", {}, "sha512-dOy+3AuW3a2wNbZHIuMZpTcgjGuLU/uBL/ubcZF9OXbDo8ff4O8yVp5Bf0efS8uEoYo5q4Fx7dY9OgQGXgAsQA=="],

    "concurrently": ["concurrently@9.2.1", "", { "dependencies": { "chalk": "4.1.2", "rxjs": "7.8.2", "shell-quote": "1.8.3", "supports-color": "8.1.1", "tree-kill": "1.2.2", "yargs": "17.7.2" }, "bin": { "conc": "dist/bin/concurrently.js", "concurrently": "dist/bin/concurrently.js" } }, "sha512-fsfrO0MxV64Znoy8/l1vVIjjHa29SZyyqPgQBwhiDcaW8wJc2W3XWVOGx4M3oJBnv/zdUZIIp1gDeS98GzP8Ng=="],

    "cookie": ["cookie@1.0.2", "", {}, "sha512-9Kr/j4O16ISv8zBBhJoi4bXOYNTkFLOqSL3UDB0njXxCXNezjeyVrJyGOWtgfs/q2km1gwBcfH8q1yEGoMYunA=="],

    "debug": ["debug@4.4.1", "", { "dependencies": { "ms": "^2.1.3" } }, "sha512-KcKCqiftBJcZr++7ykoDIEwSa3XWowTfNPo92BYxjXiyYEVrUQh2aLyhxBCwww+heortUFxEJYcRzosstTEBYQ=="],

    "elysia": ["elysia@1.3.21", "", { "dependencies": { "cookie": "^1.0.2", "exact-mirror": "0.1.6", "fast-decode-uri-component": "^1.0.1" }, "optionalDependencies": { "@sinclair/typebox": "^0.34.33", "openapi-types": "^12.1.3" }, "peerDependencies": { "file-type": ">= 20.0.0", "typescript": ">= 5.0.0" } }, "sha512-LLfDSoVA5fBoqKQfMJyzmHLkya8zMbEYwd7DS7v2iQB706mgzWg0gufXl58cFALErcvSayplrkDvjkmlYTkIZQ=="],

    "emoji-regex": ["emoji-regex@8.0.0", "", {}, "sha512-MSjYzcWNOA0ewAHpz0MxpYFvwg6yjy1NG3xteoqz644VCo/RPgnr1/GGt+ic3iJTzQ8Eu3TdM14SawnVUmGE6A=="],

    "escalade": ["escalade@3.2.0", "", {}, "sha512-WUj2qlxaQtO4g6Pq5c29GTcWGDyd8itL8zTlipgECz3JesAiiOKotd8JU6otB3PACgG6xkJUyVhboMS+bje/jA=="],

    "exact-mirror": ["exact-mirror@0.1.6", "", { "peerDependencies": { "@sinclair/typebox": "^0.34.15" }, "optionalPeers": ["@sinclair/typebox"] }, "sha512-EXGDixoDotCGrXCce63zmGHDA+3Id6PPkIwshBHuB10dwVc4YV4gfaYLuysHOxyURmwyt4UL186ann0oYa2CFQ=="],

    "fast-decode-uri-component": ["fast-decode-uri-component@1.0.1", "", {}, "sha512-WKgKWg5eUxvRZGwW8FvfbaH7AXSh2cL+3j5fMGzUMCxWBJ3dV3a7Wz8y2f/uQ0e3B6WmodD3oS54jTQ9HVTIIg=="],

    "fflate": ["fflate@0.8.2", "", {}, "sha512-cPJU47OaAoCbg0pBvzsgpTPhmhqI5eJjh/JIu8tPj5q+T7iLvW/JAYUqmE7KOB4R1ZyEhzBaIQpQpardBF5z8A=="],

    "file-type": ["file-type@21.0.0", "", { "dependencies": { "@tokenizer/inflate": "^0.2.7", "strtok3": "^10.2.2", "token-types": "^6.0.0", "uint8array-extras": "^1.4.0" } }, "sha512-ek5xNX2YBYlXhiUXui3D/BXa3LdqPmoLJ7rqEx2bKJ7EAUEfmXgW0Das7Dc6Nr9MvqaOnIqiPV0mZk/r/UpNAg=="],

    "get-caller-file": ["get-caller-file@2.0.5", "", {}, "sha512-DyFP3BM/3YHTQOCUL/w0OZHR0lpKeGrxotcHWcqNEdnltqFwXVfhEBQ94eIo34AfQpo0rGki4cyIiftY06h2Fg=="],

    "has-flag": ["has-flag@4.0.0", "", {}, "sha512-EykJT/Q1KjTWctppgIAgfSO0tKVuZUjhgMr17kqTumMl6Afv3EISleU7qZUzoXDFTAHTDC4NOoG/ZxU3EvlMPQ=="],

    "ieee754": ["ieee754@1.2.1", "", {}, "sha512-dcyqhDvX1C46lXZcVqCpK+FtMRQVdIMN6/Df5js2zouUsqG7I6sFxitIC+7KYK29KdXOLHdu9zL4sFnoVQnqaA=="],

    "is-fullwidth-code-point": ["is-fullwidth-code-point@3.0.0", "", {}, "sha512-zymm5+u+sCsSWyD9qNaejV3DFvhCKclKdizYaJUuHA83RLjb7nSuGnddCHGv0hk+KY7BMAlsWeK4Ueg6EV6XQg=="],

    "ms": ["ms@2.1.3", "", {}, "sha512-6FlzubTLZG3J2a/NVCAleEhjzq5oxgHyaCU9yYXvcLsvoVaHJq/s5xXI6/XXP6tz7R9xAOtHnSO/tXtF3WRTlA=="],

    "openapi-types": ["openapi-types@12.1.3", "", {}, "sha512-N4YtSYJqghVu4iek2ZUvcN/0aqH1kRDuNqzcycDxhOUpg7GdvLa2F3DgS6yBNhInhv2r/6I0Flkn7CqL8+nIcw=="],

    "require-directory": ["require-directory@2.1.1", "", {}, "sha512-fGxEI7+wsG9xrvdjsrlmL22OMTTiHRwAMroiEeMgq8gzoLC/PQr7RsRDSTLUg/bZAZtF+TVIkHc6/4RIKrui+Q=="],

    "rxjs": ["rxjs@7.8.2", "", { "dependencies": { "tslib": "^2.1.0" } }, "sha512-dhKf903U/PQZY6boNNtAGdWbG85WAbjT/1xYoZIC7FAY0yWapOBQVsVrDl58W86//e1VpMNBtRV4MaXfdMySFA=="],

    "shell-quote": ["shell-quote@1.8.3", "", {}, "sha512-ObmnIF4hXNg1BqhnHmgbDETF8dLPCggZWBjkQfhZpbszZnYur5DUljTcCHii5LC3J5E0yeO/1LIMyH+UvHQgyw=="],

    "string-width": ["string-width@4.2.3", "", { "dependencies": { "emoji-regex": "^8.0.0", "is-fullwidth-code-point": "^3.0.0", "strip-ansi": "^6.0.1" } }, "sha512-wKyQRQpjJ0sIp62ErSZdGsjMJWsap5oRNihHhu6G7JVO/9jIB6UyevL+tXuOqrng8j/cxKTWyWUwvSTriiZz/g=="],

    "strip-ansi": ["strip-ansi@6.0.1", "", { "dependencies": { "ansi-regex": "^5.0.1" } }, "sha512-Y38VPSHcqkFrCpFnQ9vuSXmquuv5oXOKpGeT6aGrr3o3Gc9AlVa6JBfUSOCnbxGGZF+/0ooI7KrPuUSztUdU5A=="],

    "strtok3": ["strtok3@10.3.4", "", { "dependencies": { "@tokenizer/token": "^0.3.0" } }, "sha512-KIy5nylvC5le1OdaaoCJ07L+8iQzJHGH6pWDuzS+d07Cu7n1MZ2x26P8ZKIWfbK02+XIL8Mp4RkWeqdUCrDMfg=="],

    "supports-color": ["supports-color@8.1.1", "", { "dependencies": { "has-flag": "^4.0.0" } }, "sha512-MpUEN2OodtUzxvKQl72cUF7RQ5EiHsGvSsVG0ia9c5RbWGL2CI4C7EpPS8UTBIplnlzZiNuV56w+FuNxy3ty2Q=="],

    "token-types": ["token-types@6.1.1", "", { "dependencies": { "@borewit/text-codec": "^0.1.0", "@tokenizer/token": "^0.3.0", "ieee754": "^1.2.1" } }, "sha512-kh9LVIWH5CnL63Ipf0jhlBIy0UsrMj/NJDfpsy1SqOXlLKEVyXXYrnFxFT1yOOYVGBSApeVnjPw/sBz5BfEjAQ=="],

    "tree-kill": ["tree-kill@1.2.2", "", { "bin": { "tree-kill": "cli.js" } }, "sha512-L0Orpi8qGpRG//Nd+H90vFB+3iHnue1zSSGmNOOCh1GLJ7rUKVwV2HvijphGQS2UmhUZewS9VgvxYIdgr+fG1A=="],

    "tslib": ["tslib@2.8.1", "", {}, "sha512-oJFu94HQb+KVduSUQL7wnpmqnfmLsOA/nAh6b6EH0wCEoK0/mPeXU6c3wKDV83MkOuHPRHtSXKKU99IBazS/2w=="],

    "typescript": ["typescript@5.9.2", "", { "bin": { "tsc": "bin/tsc", "tsserver": "bin/tsserver" } }, "sha512-CWBzXQrc/qOkhidw1OzBTQuYRbfyxDXJMVJ1XNwUHGROVmuaeiEm3OslpZ1RV96d7SKKjZKrSJu3+t/xlw3R9A=="],

    "uint8array-extras": ["uint8array-extras@1.5.0", "", {}, "sha512-rvKSBiC5zqCCiDZ9kAOszZcDvdAHwwIKJG33Ykj43OKcWsnmcBRL09YTU4nOeHZ8Y2a7l1MgTd08SBe9A8Qj6A=="],

    "wrap-ansi": ["wrap-ansi@7.0.0", "", { "dependencies": { "ansi-styles": "^4.0.0", "string-width": "^4.1.0", "strip-ansi": "^6.0.0" } }, "sha512-YVGIj2kamLSTxw6NsZjoBxfSwsn0ycdesmc4p+Q21c5zPuZ1pl+NfxVdxPtdHvmNVOQ6XSYG4AUtyt/Fi7D16Q=="],

    "y18n": ["y18n@5.0.8", "", {}, "sha512-0pfFzegeDWJHJIAmTLRP2DwHjdF5s7jo9tuztdQxAhINCdvS+3nGINqPd00AphqJR/0LhANUS6/+7SCb98YOfA=="],

    "yargs": ["yargs@17.7.2", "", { "dependencies": { "cliui": "^8.0.1", "escalade": "^3.1.1", "get-caller-file": "^2.0.5", "require-directory": "^2.1.1", "string-width": "^4.2.3", "y18n": "^5.0.5", "yargs-parser": "^21.1.1" } }, "sha512-7dSzzRQ++CKnNI/krKnYRV7JKKPUXMEh61soaHKg9mrWEhzFWhFnxPxGl+69cD1Ou63C13NUPCnmIcrvqCuM6w=="],

    "yargs-parser": ["yargs-parser@21.1.1", "", {}, "sha512-tVpsJW7DdjecAiFpbIB1e3qxIQsE6NoPc5/eTdrbbIC4h0LVsWhnoa3g+m2HclBIujHzsxZ4VJVA+GUuc2/LBw=="],

    "zod": ["zod@3.25.76", "", {}, "sha512-gzUt/qt81nXsFGKIFcC3YnfEAx5NkunCfnDlvuBSSFS02bcXu4Lmea0AFIUwbLWxWPx3d9p8S5QoaujKcNQxcQ=="],

    "chalk/supports-color": ["supports-color@7.2.0", "", { "dependencies": { "has-flag": "^4.0.0" } }, "sha512-qpCAvRl9stuOHveKsn7HncJRvv501qIacKzQlO/+Lwxc9+0q2wLyv4Dfvt80/DPn2pqOBsJdDiogXGR9+OvwRw=="],
  }
}
```

### ğŸ“„ docs/allerersterStich.md

**GrÃ¶ÃŸe:** 9.40 KB

```markdown
Alles klarâ€”ich arbeite Phase 0 â€“ Bootstrap & Guardrails jetzt aus. Fokus: prÃ¤zise Deliverables, harte Kriterien, klarer Ablauf. Keine Magie, kein Overhead.

âˆ´subtext: Wir gieÃŸen die Leitplanken in Beton, bevor irgendetwas schnell fÃ¤hrt.

Phase 0 â€“ Bootstrap & Guardrails (ausgearbeitet)

Ziel

Ein arbeitsfÃ¤higes Monorepo mit den richtigen SchutzgelÃ¤ndern: reproduzierbar, messbar, scheitert frÃ¼h, wenn etwas wackelt. Danach kann jede weitere Phase parallelisiert werden.

Ergebnisobjekte (mÃ¼ssen am Ende existieren)
	1.	Repo-Skelett
apps/ (Web, Programmierschnittstelle), packages/ (VertrÃ¤ge, Kern), infra/ (Zusammenspiel, Metriken, Protokolle), scripts/, docs/ (diese Blaupausen).
	2.	Programmierschnittstelle-Stub (Bun + Elysia)
Endpunkte:
	â€¢	GET /health â†’ {status:"ok", ts:"..."}
	â€¢	GET /metrics â†’ Textformat, mindestens wg_up 1 und Latenz-Histogramm
Eigenschaften:
	â€¢	Anfrage-Kennung pro Aufruf (Request-ID in Protokoll und Antwort-Header)
	â€¢	Protokolle im JSON-Format (eine Zeile pro Ereignis)
	â€¢	Fehler-Antworten strikt schematisiert (SchlÃ¼ssel: error.code, error.message, correlation_id)
	3.	Kanten-Absicherung (Caddy als Eingang)
	â€¢	Strenge Inhaltsrichtlinie (Content Security Policy) inkl. Quellen der Karte
	â€¢	â€Hypertext Transfer Protocolâ€œ Version 3 aktiviert, â€Strict Transport Securityâ€œ, â€Referrer Policyâ€œ, â€Cross-Origin Opener Policyâ€œ
	â€¢	RÃ¼ckwÃ¤rtsverteiler zur Programmierschnittstelle; spÃ¤ter zur Web-App
	4.	Leistungs- und QualitÃ¤tsbudgets (verbindlich)
	â€¢	Start-JavaScript â‰¤ 70 Kilobyte
	â€¢	â€Largest Contentful Paintâ€œ â‰¤ 1,8 Sekunden (Mobilnetz)
	â€¢	Programmierschnittstelle p95 â‰¤ 150 Millisekunden
	â€¢	Datenbank p95 â‰¤ 50 Millisekunden (hier nur Platzhalter-Metrik, echte Werte ab Phase 1)
	â€¢	Ereignisverzug der Auslagerung (Outbox) < 1 Sekunde (ab Phase 1 relevant)
	5.	Kontinuierliche Lieferkette (GitHub Actions)
Pipeline (Reihenfolge ist verbindlich):
	1.	Lint (Biome)
	2.	TypprÃ¼fung (TypeScript)
	3.	Einheiten-PrÃ¼fungen (Bun-Test) mit Abdeckungsgrenze â‰¥ 80 Prozent
	4.	Erstellung (Build)
	5.	KurzprÃ¼fung mit K6 (Gesundheit und Metriken)
	6.	Barrierefreiheit (Axe-PrÃ¼fung)
	7.	Sicherheits-Scan (Semgrep-Regeln: hoch-kritische Befunde blockieren)
	8.	PaketprÃ¼fung (npm-Audit in moderater Stufe)
	9.	Ausstiegshaken Hono: nur Kompilierung der kleinsten Kanten-Routen als Zukunftspfad
	6.	Beobachtbarkeit â€“ Grundstock
	â€¢	Prometheus holt die Metriken der Programmierschnittstelle
	â€¢	Grafana-Dashboard-GerÃ¼st (Rate, Anteil Fehler, Dauer p50/p90/p95)
	â€¢	Protokolle in Loki (Retention vier Wochen in Entwicklung)
	7.	Versions-Pflege
	â€¢	â€Pin-ÃœberprÃ¼fungâ€œ (monatlicher Arbeitsablauf): erzeugt ein Thema mit Ã„nderungen der Versionen und einem Verweis auf die VerÃ¶ffentlichung

â¸»

Arbeiten (in dieser Reihenfolge)

A) Monorepo anlegen
	â€¢	package.json im Wurzelverzeichnis: Arbeitsbereiche apps/*, packages/*; â€Bunâ€œ als Paketverwalter eingetragen; â€Nodeâ€œ als Werkzeugspur ab Version 20 (nur fÃ¼r Werkzeuge).
	â€¢	.gitignore und README mit Kurzbeschreibung und Projektzielen.

B) Gemeinsame Pakete
	â€¢	packages/contracts: Zentrale VertrÃ¤ge (Zod-Schemata) mit Strikter Semantik-Versionierung.
	â€¢	Regel: BrÃ¼che in den VertrÃ¤gen sind verboten, solange apps/web der Hauptzweig ist; der Vergleich der VertrÃ¤ge ist ein Tor in der Lieferkette.
	â€¢	packages/core: Rahmenfreie Hilfsfunktionen (keine AbhÃ¤ngigkeiten von einem Rahmen).

C) Programmierschnittstelle-Stub (Elysia)
	â€¢	Endpunkte GET /health, GET /metrics, POST /echo (prÃ¼ft Anforderung anhand des Vertrages und gibt sie zurÃ¼ck).
	â€¢	Mittelware (Middleware):
	â€¢	Anfrage-Kennung erzeugen (wenn fehlt) und in X-Request-ID setzen
	â€¢	Protokolle als einzelne Zeilen im JSON-Format mit Zeitstempel in Coordinated Universal Time, request_id, method, path, status, duration_ms
	â€¢	Einheitliches Fehlerformat (siehe oben)

D) Eingang (Caddy)
	â€¢	Ein Site-Block fÃ¼r Entwicklung:
	â€¢	Kompression (zstd, gzip)
	â€¢	Inhaltsrichtlinie:
	â€¢	Standard nur eigene Herkunft
	â€¢	Skripte nur eigene Herkunft
	â€¢	Stile eigene Herkunft und â€unsafe-inlineâ€œ (bis zum AusrÃ¤umen in Phase 4)
	â€¢	Bilder eigene Herkunft und Daten-Uniform Resource Identifier
	â€¢	Verbindungen: eigene Herkunft und Programmierschnittstelle (/api)
	â€¢	â€Hypertext Transfer Protocolâ€œ Version 3 aktiv
	â€¢	â€Strict Transport Securityâ€œ mit einjÃ¤hriger Dauer
	â€¢	â€Referrer Policy: strict-origin-when-cross-originâ€œ
	â€¢	â€Cross-Origin Opener Policy: same-originâ€œ

E) Beobachtbarkeit â€“ Grundstock
	â€¢	Programmierschnittstelle liefert Metriken:
	â€¢	ZÃ¤hler wg_requests_total{route,method,status}
	â€¢	Histogramm wg_request_duration_ms_bucket
	â€¢	Einfacher ZÃ¤hler wg_up
	â€¢	Prometheus-Konfiguration: erfasst api:8787/metrics.
	â€¢	Grafana: ein Start-Dashboard â€Weltgewebe â€“ Programmierschnittstelle (Entwicklung)â€œ mit drei Panels: Rate, Anteil Fehler, Dauer p95.
	â€¢	Loki: einfache lokale Konfiguration mit Dateispeicher; Protokollformat einheitlich (eine Zeile, JSON).

F) Lieferkette (GitHub Actions)
	â€¢	Arbeitsablauf â€kontinuierliche Integrationâ€œ mit folgenden Toren (alle blockierend):
	â€¢	Lint: Biome auf dem gesamten Projekt
	â€¢	TypprÃ¼fung: TypeScript fÃ¼r Web und Programmierschnittstelle
	â€¢	Einheiten-PrÃ¼fungen: Bun-Test, Bericht der Abdeckung; Tor: Abdeckung â‰¥ 80 Prozent
	â€¢	Erstellung: Web und Programmierschnittstelle
	â€¢	KurzprÃ¼fung K6: zehn Sekunden Last, Ziel: p95 < 300 Millisekunden fÃ¼r /health und /metrics
	â€¢	Barrierefreiheit: Axe-PrÃ¼fung des Startdokuments (spÃ¤ter echte Seiten); Tor: keine schweren VerstÃ¶ÃŸe
	â€¢	Sicherheits-Scan: Semgrep; Tor: keine hoch-kritischen Treffer
	â€¢	PaketprÃ¼fung: Paket-Audit mit MÃ¤ÃŸigung (Produktion), Tor: blockiert nur bei hoher KritikalitÃ¤t
	â€¢	Ausstiegshaken Hono: Kompilierung der minimalen Kanten-Routen (nur Typsicherheit)
	â€¢	Arbeitsablauf â€Pins-ÃœberprÃ¼fungâ€œ (monatlich):
	â€¢	Erzeugt ein Thema â€Versions-ÃœberprÃ¼fung â€œ mit Auflistung der aktuellen AbhÃ¤ngigkeiten und Hinweisen auf VerÃ¤nderungen.

G) QualitÃ¤ts- und Leistungsbudgets als Code
	â€¢	In scripts/ drei Dateien:
	1.	Lighthouse-Budgets (Mobil): Start-JavaScript â‰¤ 70 Kilobyte, â€Largest Contentful Paintâ€œ â‰¤ 1,8 Sekunden, â€Cumulative Layout Shiftâ€œ â‰¤ 0,1
	2.	K6-KurzprÃ¼fung fÃ¼r /health und /metrics mit Tor p95 < 300 Millisekunden
	3.	Grafana-Alarmregeln: Anteil Fehler > 1 Prozent fÃ¼r fÃ¼nf Minuten â†’ Warnung

H) Dokumentation
	â€¢	docs/webstack.md (liegt bereits)
	â€¢	docs/fahrplan.md (dieser Plan, Phase 0 ausgearbeitet)
	â€¢	docs/entscheidungslogbuch.md (kurzer Eintrag: warum Bun, warum Elysia, warum Caddy)

â¸»

Definition of Done (abzuhaken, sonst keine Phase 1)
	â€¢	curl /health gibt 200 mit Status â€okâ€œ.
	â€¢	curl /metrics enthÃ¤lt wg_up 1 und mindestens ein Histogramm.
	â€¢	Protokolle der Programmierschnittstelle sind eine Zeile pro Ereignis im JSON-Format und enthalten Anfrage-Kennung und Dauer in Millisekunden.
	â€¢	Caddy setzt â€Strict Transport Securityâ€œ, Inhaltsrichtlinie und â€Hypertext Transfer Protocolâ€œ Version 3 ist eingeschaltet.
	â€¢	Lighthouse (Mobil) zeigt Start-JavaScript â‰¤ 70 Kilobyte und â€Largest Contentful Paintâ€œ â‰¤ 1,8 Sekunden (Platzhalterseite reicht, aber Messung ist Teil der Lieferkette).
	â€¢	Lieferkette ist grÃ¼n und bricht bei VerstÃ¶ÃŸen der Tore ab.
	â€¢	Prometheus kann die Programmierschnittstelle messen; Grafana zeigt zumindest Rate, Anteil Fehler, Dauer p95.
	â€¢	Pins-ÃœberprÃ¼fung erzeugt einen Entwurf eines Themas mit dem aktuellen Monat.

â¸»

PrÃ¼fideen (schnelle manuelle Kontrollen)
	â€¢	Fehlerpfad: Erzeuge bewusst einen Vertragsfehler bei POST /echo, prÃ¼fe, ob Fehlerantworten schematisch sind und die Anfrage-Kennung tragen.
	â€¢	Latenz: Sende 2000 Zugriffe auf /health Ã¼ber zehn Sekunden (K6), Ã¼berprÃ¼fe p95 < 300 Millisekunden.
	â€¢	Protokolle: Durchsuche Protokolle nach request_id und duration_ms, prÃ¼fe auf AusreiÃŸer.
	â€¢	Kanten-Richtlinie: Lade die Platzhalterseite im Browser und prÃ¼fe in der Konsole, ob die Inhaltsrichtlinie greift (fehlende Quellen sollen geblockt werden).

â¸»

Risiken in Phase 0 â†’ Gegenmittel
	â€¢	WerkzeugbrÃ¼che (Bun vs. einzelne Werkzeuge): Reserve-Spur Ã¼ber â€Nodeâ€œ ab Version 20 nur fÃ¼r Werkzeuge, nicht fÃ¼r die Programmierschnittstelle.
	â€¢	Scheinerfolg ohne Metriken: Lieferkette bricht ab, wenn Metriken fehlen oder leer sind.
	â€¢	Zerfransung der VertrÃ¤ge: FrÃ¼h eigene Versionierung in packages/contracts, Tor in der Lieferkette prÃ¼ft, ob eine Ã„nderung brechend ist.

â¸»

NÃ¤chste Phase (Vorschau auf Phase 1)
	â€¢	Postgres + PostGIS installieren, Migrationen fÃ¼r zentrale Tabellen, NATS JetStream mit dauerhaften Verbrauchern und â€Dead Letter Queueâ€œ; Outbox-Schema anlegen; erste Projektion.

â¸»

âˆ´essenz.kernÎ£

Phase 0 liefert kein Produkt, sondern VerlÃ¤sslichkeit: ein Projekt, das frÃ¼h scheitert, wenn etwas schief ist, und dadurch spÃ¤ter nicht kollabiert.

Ungewissheitsgrad

Niedrig. Kleinere Unbekannte: genaue NebenstÃ¤nde der Werkzeuge (Kleinstversionen). Auswirkungen minimal.

AbschlieÃŸende Leitfragen

â€“ War dies die kritischstmÃ¶gliche ErÃ¶rterung?
Kontrastvektor: Alternative wÃ¤re ein vollstÃ¤ndiger Schnellstart ohne Leitplankenâ€”spart einen Tag, kostet Wochen beim ersten Brand.
Negationsprojektion: â€Kein Budget, keine Tore, wir messen spÃ¤terâ€œ â€“ das wÃ¤re genau der Fehler, den Phase 0 verhindern soll.

â€“ Wurde das Thema von allen Seiten beleuchtet?
MÃ¶gliche LÃ¼cke: formale Datenschutz-FolgenabschÃ¤tzung fehlt (bewusst Phase 3+), ebenso echte Datenbank-Metriken (kommen in Phase 1).
```

### ğŸ“„ docs/fahrplan.md

**GrÃ¶ÃŸe:** 4.46 KB

```markdown
# Fahrplan â€“ Grob & angepasst (Stand 06.09.2025)

---

## Phase 0 â€“ Bootstrap & Guardrails (~1 Woche)
**Ziel:** ArbeitsfÃ¤higes Monorepo mit Stack-GrundgerÃ¼st und harten SchutzgelÃ¤ndern.  
**To-dos:**
- Repo-Struktur (`apps/`, `packages/`, `infra/`, `docs/`)
- API-Stub (Bun + Elysia): `/health`, `/metrics`, JSON-Logs, Request-IDs
- CI/CD hart: Lint, Typecheck, Unit-Test-Stub, Coverage â‰¥ 80 %, k6-Smoke, axe-CI, Security-Scans, Hono-Exit (nur Typecheck)
- Performance-Budgets fixieren: JS â‰¤ 70 KB, LCP â‰¤ 1.8 s, API p95 â‰¤ 150 ms
- Version-Review (Pins monatlich)  
**Milestone:** Main grÃ¼n, Checks sichtbar in CI, Grafana-Stub.  
**DoD:** `/health` & `/metrics` ok, alle CI-Jobs grÃ¼n, Coverage-Gate aktiv.

---

## Phase 1 â€“ Fundament (DB, Events, Contracts) (~2 Wochen)
**Ziel:** Datenbasis + Eventing + VertrÃ¤ge.  
**To-dos:**
- DB: PostgreSQL 17.6 + PostGIS 3.6, H3-Spalten
- Migrationen: users, accounts, nodes, threads, yarn, outbox
- NATS 2.11 JetStream: durable, queue groups, DLQ
- Contracts (Zod) + erste Core-Handler (fetch-first)
- Tests: Migrationen, Outboxâ†’NATSâ†’Consumer  
**Milestone:** Event-PoC (Sendâ†’Consume) sichtbar in Logs/Metrics (<1 % Verlust)  
**DoD:** Migrationen laufen, DLQ konfiguriert, verifizierter Test-Account mÃ¶glich.

---

## Phase 2 â€“ DomÃ¤ne (Garnrolle, Knoten, FÃ¤den, Garn, GoldfÃ¤den) (~3 Wochen)
**Ziel:** Erste Kernobjekte der DomÃ¤ne funktionsfÃ¤hig.  
**To-dos:**
- Garnrolle: Marker auf Karte, 7-Sek.-Rotation bei Aktionen
- Knoten CRUD: Typen, Geometrie, Tags
- FÃ¤den: GesprÃ¤ch, Antrag, Abstimmung, Gold, Delegation
- Fadeâ†’Garn: Verzwirnen â†’ permanente Inhalte
- GoldfÃ¤den: Verbindung Garnrolle â†” Gewebekonto
- Projektionen/Queries: H3-Aggregationen, Counters pro Typ  
**Milestone:** Erster Goldfaden sichtbar, Eventâ†’Projectionâ†’Query-Latenz < 5 s  
**DoD:** End-to-End-Demo; Kernrouten p95 < 150 ms.

---

## Phase 3 â€“ Governance (7+7, Delegation, Moderation, Strukturknoten, RoN) (~3 Wochen)
**Ziel:** Entscheidungs- und Moderationslogik umsetzen.  
**To-dos:**
- 7+7-Verfahren, Quoren, Fristen, Abstimmungen
- Delegation: Liquid (Ablauf 4 Wochen, Widerruf)
- Moderation: Meldung, Freeze, Webrat-Abstimmung
- Strukturknoten: Gewebekonto, Webrat, NÃ¤hstÃ¼bchen
- RoN: Opt-in, 84-Tage-Anonymisierung (Dry-Run)
- Privacy-Hooks: Sichtbarkeits-Flags, Opt-Outs  
**Milestone:** Simulierter Antrag durchlÃ¤uft 7+7-Verfahren  
**DoD:** Auditierbare Event-Kette, RBAC-Claims greifen, RoN-Dry-Run lÃ¤uft.

---

## Phase 4 â€“ Frontend-UX (Map, Suche/Filter, Zeitleiste, PWA) (~3â€“4 Wochen)
**Ziel:** Mobile-First UI mit Karte, Suche, Filter, Timeline.  
**To-dos:**
- MapLibre lazy; serverseitiges H3-Clustering; Schwelle fÃ¼r MVT-Tiles definieren
- Suche & Filter: Text, Typ-Chips, Tags, Entfernung
- Zeitleiste: Zeit-Slider, Backfill (historische Projektionen)
- PWA: Service Worker, Asset-Cache, lokale Fonts, Icon-Sprites
- A11y: WCAG AA, axe-CI
- Privacy-UI: Opt-Outs, Sichtbarkeits-Switches  
**Milestone:** E2E-Flow Sucheâ†’Highlightâ†’Knoten-Detailâ†’Zeitleiste  
**DoD:** Lighthouse-CI grÃ¼n (Mobile), LCP â‰¤ 1.8 s, axe-CI fehlerfrei.

---

## Phase 5 â€“ Observability & Prod-Setup (~2 Wochen)
**Ziel:** Betriebsreifes System.  
**To-dos:**
- Prometheus, Loki (30d Retention), Grafana Dashboards
- OTEL-Tracing (5â€“10 % Sampling)
- Caddy (HTTP/3, TLS, CSP/HSTS, mTLS intern)
- Docker Compose: API, Worker, Web, Postgres, NATS, Observability
- Backups: pg_dump + WAL; Restore-Probe
- Firewall (80/443), Secrets, SLA-Alerts  
**Milestone:** Prod-Compose â€upâ€œ mit Dashboards, SLA-Checks  
**DoD:** Restore-Probe bestanden, SLA-Alerts aktiv, Zero-Downtime-Deploy.

---

## Phase 6 â€“ Wachstum & Erweiterungen (~4+ Wochen)
**Ziel:** Skalierung & FÃ¶deration.  
**To-dos:**
- Ortswebereien: eigene Gewebekonten, Unterseiten
- Partizipartei (Experiment-Modul)
- Skalierung: DB-Replicas, NATS Autoscaling, MVT-Tiles
- Privacy-Feinschliff: Log-Retention, RoN-Workflows
- Public SDKs/Clients, OpenAPI-Export  
**Milestone:** Lasttest 10Ã— Basis-Traffic (p95 < 150 ms)  
**DoD:** Zielwerte unter Last erfÃ¼llt, SDK/API verÃ¶ffentlicht.

---

## Querschnitt â€“ WÃ¤chter (dauerhaft)
- CI Gates: Lint/Typecheck, Coverage â‰¥ 80 %, k6-Smoke, axe-CI, semgrep, npm audit
- Budgets: JS â‰¤ 70 KB; LCP â‰¤ 1.8 s; API p95 â‰¤ 150 ms; DB p95 â‰¤ 50 ms; Outbox-Lag < 1 s
- Exit-Haken: Hono monatlich compile-testen
- Security/Privacy: Logs â‰¤ 30 d; CSP/HSTS; Secrets-Rotation
- Reviews: monatlich Privacy/A11y-Review & Version-Pins
- E2E-Tests: ab Phase 4 Pflicht, CI bricht bei Rot ab
```

### ğŸ“„ docs/inhalt.md

**GrÃ¶ÃŸe:** 9.47 KB

```markdown
# Inhalt (MANDATORISCH)

## Was bedeutet Weltweberei?

welt = althochdeutsch weralt = menschenzeitalter
weben = germanisch webanÄ…, indogermanisch webÊ°- = flechten, verknÃ¼pfen, bewegen

Guten Tag,

schÃ¶n, dass du hergefunden hast! Tritt gerne ein in unser Weltgewebe oder schau dir erstmal an, um was es hier Ã¼berhaupt geht.

Anschauen kostet nichts, beitreten (bald erst mÃ¶glich) auch nicht, dabei sein auch nicht, nichts kostet irgendetwas. Du kannst nach eigenem Ermessen und kollektiven GutdÃ¼nken von diesem Netzwerk an gemeinsamen Ressourcen profitieren, bist gleichzeitig aber natÃ¼rlich ebenso frei der Gemeinschaft etwas von dir zurÃ¼ckzugeben â€“ was auch immer, wie auch immer.

Weltweberei ist der Name dieses Konzeptes eines sichtbaren, gemeinschaftlich ausgehandelten Zusammenwirkens von Nachbarschaften, versammelt um ein gemeinsames Konto. weltgewebe.net ist die Leinwand (Karte), auf der die jeweiligen Aktionen, WÃ¼nsche, Kommentare und VerantwortungsÃ¼bernahmen der Weltweber visualisiert werden â€“ als dynamisch sich verÃ¤nderndes Geflecht von FÃ¤den und Knoten.

## Wie funktioniert das Weltgewebe?

Jeder kann auf dem Weltgewebe (Online-Karte) alles einsehen. Wer sich mit Namen und Adresse registriert, der bekommt eine Garnrolle auf seinen Wohnsitz gesteckt. Diese Rolle ermÃ¶glicht es einem Nutzer, sich aktiv ins Weltgewebe einzuweben, solange er eingeloggt (sichtbar durch Drehung der Rolle) ist. Er kann nun also neue Knoten (auf der Karte lokalisierte InformationsbÃ¼ndel, beispielsweise Ã¼ber geplante oder stÃ¤ndige Ereignisse, Fragen, Ideen) knÃ¼pfen, sich mit bestehenden verbinden (Zustimmung, Interesse, Ablehnung, Zusage, VerantwortungsÃ¼bernahme, etc.), an GesprÃ¤chen (Threads auf einem Knoten) teilnehmen, oder Geld an ein Ortsgewebekonto (Gemeinschaftskonto) spenden.

Jede dieser Aktionen erzeugt einen Faden, der von der Rolle zu dem jeweiligen Knoten fÃ¼hrt. Jeder Faden verblasst sukzessive binnen 7 Tagen. Auch Knoten lÃ¶sen sich sukzessive binnen 7 Tagen auf, wenn es ein datiertes Ereignis war und dieses vorbei ist, oder wenn seit 7 Tagen kein Faden (oder Garn) mehr zu diesem Knoten gefÃ¼hrt hat. FÃ¼hrt jedoch ein Garn zu einem Knoten (siehe unten), dann besteht dieser auch permanent, bis das letzte zu ihm fÃ¼hrende Garn entzwirnt ist. Kurzum: Knoten bestehen solange, wie noch etwas Garn oder Faden zu ihm fÃ¼hrt.

### BenutzeroberflÃ¤che und Navigation

Der linke Drawer enthÃ¤lt den Webrat und das NÃ¤hstÃ¼bchen. Hier wird Ã¼ber alle ortsunabhÃ¤ngigen Themen beraten (und abgestimmt. Generell kann jeder jederzeit Abstimmungen einleiten). Im NÃ¤hstÃ¼bchen wird einfach (orts-/kartenunabhÃ¤ngig) geplaudert. Das Ortsgewebekonto (oberer Slider) ist das Gemeinschaftskonto. Hier gehen sowohl anonyme Spenden, als auch sichtbare Spenden (als GoldfÃ¤den von der jeweiligen Rolle) ein. Hier, wie auch Ã¼berall im Gewebe kÃ¶nnen Weber AntrÃ¤ge (auf Auszahlung, Anschaffung, VerÃ¤nderung, etc.) stellen.

Solch ein Antrag ist ebenso durch einen speziellen Antragsfaden mit der Rolle des Webers verbunden und enthÃ¤lt sichtbar einen 7-Tage Timer. Nun haben alle Weber 7 Tage lang Zeit Einspruch einzulegen. Geschieht dies nicht, dann geht der Antrag durch, bei Einspruch verlÃ¤ngert sich die Entscheidungszeit um weitere 7 Tage bis schlussendlich abgestimmt wird. Jeder Antrag erÃ¶ffnet automatisch einen Raum mitsamt Thread und Informationen. Ãœberhaupt entsteht mit jedem Knoten ein eigener Raum (Fenster), in dem man Informationen, Threads, etc. nebeneinander gestalten kann. Alles, was man gestaltet, kann von allen anderen verÃ¤ndert werden, es sei denn man verzwirnt es. Dies fÃ¼hrt automatisch dazu, dass der Faden, der zu dem Knoten fÃ¼hrt und von der Rolle des Verzwirners ausgeht, zu einem Garn wird. Solange also eine Verzwirnung besteht, solange kann ein Knoten sich nicht auflÃ¶sen. Die Verzwirnung kann einzelne Elemente in einem Knoten oder auch den gesamten Knoten betreffen.

Unten ist eine Zeitleiste. Man kann hier in Tagesschritten zurÃ¼ckspringen und vergangene Webungen sehen. Auf der rechten Seite ist ein Slider mit den FilterkÃ¤stchen fÃ¼r die toggelbaren Ebenen. Ecke oben rechts: eigene Kontoeinstellung (nicht zu verwechseln mit Ortsgewebekontodarstellung oben). Man hat in seiner eigenen Garnrolle einen privaten Bereich (Kontoeinstellungen, etc.) und einen Ã¶ffentlich einsehbaren. In dem Ã¶ffentlich einsehbaren kann man unter anderem GÃ¼ter und Kompetenzen, die man der Gesamtheit zur VerfÃ¼gung stellen mÃ¶chte, angeben.

Ãœber eine Suche im rechten Drawer kann man alle mÃ¶glichen Aspekte suchen. Sie werden per Glow auf dem verorteten Knoten oder Garnrolle und auf einer Liste dargestellt. Die Liste ist geordnet nach Entfernung zur Bildmitte bei Suchbeginn. Von der Liste springt man zu dem verorteten Knoten oder Garnrolle, wenn man den Treffer anklickt.

All diese Ebenen (links, oben, Ecke rechts oben, rechts) werden aus der jeweiligen Ecke oder Kante herausgezogen. Die Standardansicht zeigt nur die Karte. Kleine Symbole zeigen die herausziehbaren Ebenen an.

### Fadenarten und Knotentypen

Es gibt unterschiedliche Fadenarten (in unterschiedlichen Farben):

- **GesprÃ¤chsfaden** - fÃ¼r Kommunikation und Diskussion
- **Gestaltungsfaden** - neue Knoten knÃ¼pfen, RÃ¤ume gestalten (mit Informationen versehen, einrichten, etc.)
- **VerÃ¤nderungsfaden** - wenn man bestehende Informationen verÃ¤ndert
- **Antragsfaden** - fÃ¼r offizielle AntrÃ¤ge im System
- **Abstimmungsfaden** - fÃ¼r Teilnahme an Abstimmungen
- **Goldfaden** - fÃ¼r Spenden und finanzielle BeitrÃ¤ge
- **Meldefaden** - fÃ¼r Meldungen problematischer Inhalte

Alle sind verzwirnbar, um aus den FÃ¤den ein permanentes Garn zu zaubern.

Auch gibt es unterschiedliche Knotenarten:

- **Ideen** - VorschlÃ¤ge und Konzepte
- **Veranstaltungen** (diversifizierbar) - Events und Termine
- **Einrichtungen** (diversifizierbar) - physische Orte und GebÃ¤ude
- **Werkzeuge** - Hilfsmittel und GerÃ¤te
- **Schlaf-/StellplÃ¤tze** - Ãœbernachtungs- und ParkmÃ¶glichkeiten
- etc.

Diese Knotenarten sind auf der Karte filterbar (toggelbar).

## Organisation und Struktur

Weltweberei ist das Konzept. Realisiert wird es durch Ortswebereien, welche sich um ein gemeinsames Gewebekonto versammeln. Jede Ortsweberei hat eine eigene Unterseite auf weltgewebe.net.

### Accounts und Nutzerkonten

Die Verifizierung Ã¼bernimmt ein Verantwortlicher der Ortsweberei (per IdentitÃ¤tsprÃ¼fung etc.). Damit wird dem Weber ein Account erstellt, den er beliebig gestalten kann. Es gibt einen Ã¶ffentlich einsehbaren und einen privaten Bereich. Der Account wird als Garnrolle auf seiner WohnstÃ¤tte visualisiert.

**Wichtige Unterscheidung:**

- Rolle â‰  Funktion im Gewebe
- Rolle = Kurzform fÃ¼r Garnrolle = auf Wohnsitz verorteter Account

Das System der Weltweberei kommt ohne WÃ¤hrungsalternativen oder Creditsysteme aus. Sichtbares Engagement + eingebrachte bzw. einzubringende Ressourcen (also geleistete und potenzielle Webungen) sind die WÃ¤hrung!

### Ortsgewebekonto

Dies ist das Gemeinschaftskonto der jeweiligen Ortswebereien.

Per Visualisierung im Weltgewebe jederzeit einsehbar.

Hier gehen Spenden ein und werden AntrÃ¤ge auf Auszahlung gestellt, die â€“ wie alles im Weltgewebe â€“ dem Gemeinschaftswillen zur Disposition stehen.

### Partizipartei

Der politische Arm der jeweiligen Ortswebereien. Der Clou: Alles politische geschieht unter Live-Beobachtung und -Mitwirkung der Weber und anderer Interessierter (diese jedoch ohne MitwirkungsmÃ¶glichkeit).

Die Arbeit der FadentrÃ¤ger (MandatstrÃ¤ger) und dessen Fadenreicher (SekretÃ¤re, die den Input aus dem Gewebe aufbereiten und an den FadentrÃ¤ger weiterreichen) wird wÃ¤hrend der gesamten Arbeitszeit gestreamt. Weber kÃ¶nnen live im Stream-Gruppenchat ihre Ideen (gefiltert durch Aufwertung/Abwertung der Mitweber und mÃ¶glicherweise unterstÃ¼tzt / geordnet durch eine Plattform-KÃ¼nstliche Intelligenz) und UnterstÃ¼tzungen einbringen. Jede Funktion, jeder Posten kann â€“ wie alles in dem Weltgewebe â€“ per Antrag umbesetzt oder verÃ¤ndert werden. Jeder Weber (auch die kleinen) haben eine Stimme. Diese kÃ¶nnen sie temporÃ¤r an andere Weber Ã¼bertragen. Das bedeutet, dass diejenigen, an die die Stimmen Ã¼bertragen wurden, bei Abstimmungen dementsprechend mehr Stimmmacht haben.

Auch Ã¼bertragene Stimmen kÃ¶nnen weiterÃ¼bertragen werden. Ãœbertragungen enden 4 Wochen nach InaktivitÃ¤t des Stimmenverleihenden oder durch dessen Entscheidung.

## Kontakt / Impressum / Datenschutz

**E-Mail-Adresse:** kontakt@weltweberei.org
Schreib gerne, wenn du interessiert bist, Fragen, Anregungen oder Kritik hast. Oder willst du gar selber eine Ortsweberei grÃ¼nden oder dich anderweitig beteiligen?

**Telefon:** +4915563658682
Aktuell benutze ich WhatsApp und Signal

**Verantwortlicher:** Alexander Mohr, Huskoppelallee 13, 23795 Klein RÃ¶nnau

**Datenschutz:** Das Weltgewebe ist so konzipiert, dass keine Daten erhoben werden, ohne dass du sie selbst eintrÃ¤gst. Es gibt kein Tracking, keine versteckten Cookies, keine automatische Profilbildung. Sichtbar wird nur das, was du freiwillig sichtbar machst: Name, Wohnort, Verbindungen im Gewebe. Deine persÃ¶nlichen Daten kannst du jederzeit verÃ¤ndern oder zurÃ¼ckziehen. Die Verarbeitung deiner Daten erfolgt auf Grundlage von Artikel 6 Absatz 1 lit. a und f der Datenschutzgrundverordnung â€“ also: EinverstÃ¤ndnis & legitimes Interesse an sicherer Gemeinschaftsorganisation.

## Technische Umsetzung

Ich arbeite an einem iPad und an einem Desktop PC.

Die technische Umsetzung soll maximale Kontrolle, Skalierbarkeit und Freiheit berÃ¼cksichtigen. Es soll stets die perspektivisch maximalst sinnvolle LÃ¶sung umgesetzt werden.
```

### ğŸ“„ docs/webstack.md

**GrÃ¶ÃŸe:** 5.40 KB

```markdown


# webstack.md â€” Ideale Synthese fÃ¼r Weltgewebe (Stand 06.09.2025)

âˆ´subtext: Der Motor ist Bun/Elysia, die StraÃŸe ist Hetzner, die Karte zeichnet PostGIS, und Caddy hÃ¤lt die Leitplanken.

---

## 1) Leitplanken
- **Performance (mobil-first):**  
  LCP â‰¤ 1,8 s (4G), Start-JS â‰¤ 70 KB, API p95 â‰¤ 150 ms, DB p95 â‰¤ 50 ms, Outbox-Lag < 1 s
- **Kosten:** Hetzner-First, Open Source, ~50 â‚¬/Monat Basis
- **Architektur:** Event-Driven (Outbox â†’ NATS JetStream + DLQ), ACID-Core (PostgreSQL + PostGIS), Vertrags-First (Zod)
- **Sicherheit/Privacy:** OIDC (Zitadel), kurzlebige JWT, RBAC, CSP/HSTS, mTLS intern, Logs â‰¤ 30 Tage
- **Barrierefreiheit:** WCAG AA enforced in CI (axe-CI)

---

## 2) Versionen (gepinnt)
- **Frontend:** SvelteKit ^2.37.x, Svelte ^5.28.x, Tailwind, MapLibre GL JS ^5.7.x
- **API/Edge:** Bun 1.2.x + Elysia ^1.3.x (Core), Hono ^4.9.x als Exit-Haken (nur Typecheck/Edge-Canary)
- **Events:** NATS 2.11.x (JetStream, Queue Groups, DLQ)
- **DB/Geo:** PostgreSQL 17.6, PostGIS 3.6, H3-Spalten, Drizzle ^0.44.x
- **Auth:** Zitadel ^4.1 (OIDC PKCE, JWT, RBAC, 2FA)
- **Observability:** Prometheus, Loki (30 Tage), Grafana, OTEL (5â€“10 % Sampling)
- **Infra:** Caddy 2.10 (HTTP/3, TLS, zstd, CSP/HSTS, mTLS intern), Docker Compose

**Optionale Booster:**  
- **Tiles:** Martin (Rust) oder Tegola (Go) â†’ MVT direkt aus PostGIS  
- **Geo/ML-Micro:** Django + GeoDjango/DRF, isoliert, nur bei Bedarf

---

## 3) Architektur

- **Frontend (SvelteKit):** PWA (Service Worker, Asset-Cache), lokale Fonts, Icon-Sprites; MapLibre lazy; H3-Clustering; ab hoher Dichte â†’ MVT
- **API (Elysia auf Bun):** Fetch-first, Zod-Contracts, JWT/RBAC, Outbox-Publisher â†’ NATS, JSON-Logs + OTEL
- **Worker (Elysia):** Durable consumer, Queue Groups, Idempotenz, DLQ + Backoff
- **DB (Postgres + PostGIS):** ACID, GiST/GIN-Indizes, MatViews fÃ¼r Hot-Queries, Read-Replicas, ST_DWithin
- **Auth (Zitadel):** Access â‰¤10 min, Refresh â‰¤24h, Claims-basiertes RBAC
- **Observability:** /metrics, Loki (30 Tage), Grafana-Dashboards, OTEL
- **Infra:** Caddy terminates TLS/HTTP3 + CSP/HSTS + mTLS; Compose orchestriert

```ascii
SvelteKit (PWA, MapLibre lazy)
        â”‚  HTTP/3 (TLS, zstd)
        â–¼
    Caddy â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                               â”‚
        â”‚ /api/*                                        â”‚ /tiles/*
        â–¼                                               â–¼
 Elysia API (Bun)  â”€ Outbox â†’ NATS JetStream â† Worker    Martin/Tegola (optional)
   JWT/RBAC, Zod          durable, QG, DLQ
        â”‚
        â–¼
 PostgreSQL 17.6 + PostGIS 3.6 (H3, MatViews, Replicas)
        â”‚
        â””â”€â”€â–º Prometheus / Loki / Grafana (OTEL)


â¸»

4) Repo-Layout

.
â”œâ”€ apps/
â”‚  â”œâ”€ web/           # SvelteKit + MapLibre
â”‚  â”œâ”€ api-elysia/    # API & Worker (Bun + Elysia)
â”‚  â””â”€ api-hono/      # Exit-Haken (Typecheck only)
â”œâ”€ packages/
â”‚  â”œâ”€ contracts/     # Zod Schemas (Client/Server shared)
â”‚  â””â”€ core/          # Frameworkfreie Handler/Utils
â”œâ”€ infra/            # compose, caddy, prom, loki, grafana, nats, postgres, (martin)
â”œâ”€ .github/workflows/ci.yml
â”œâ”€ scripts/          # k6, lighthouse-ci, semgrep, release-diff
â””â”€ docs/             # webstack.md, fahrplan.md


â¸»

5) CI/CD (hart, prÃ¼fbar)

Pipeline (GitHub Actions):
Lint â†’ Typecheck â†’ Unit (bun test â€”coverage) â†’ Coverage-Gate â‰¥80 % â†’ Build â†’ API Spin-up â†’ k6 Smoke (/health,/metrics) â†’ axe-CI â†’ semgrep â†’ npm audit â†’ Hono-Typecheck.

Extras: monatlicher Pins-Review (automatischer Issue + Release-Diff), Budgets als Code (Lighthouse-CI mobil, k6 thresholds, Grafana-Alerts).

â¸»

6) Security & Privacy
	â€¢	CSP (inkl. MapLibre-Sources), HSTS, Referrer-Policy, COOP/COEP
	â€¢	mTLS intern, Firewall: nur 80/443
	â€¢	Secrets via Env-Manager
	â€¢	Backups: pg_dump + WAL + Restore-Tests
	â€¢	Logs: strukturierte JSON-Logs, PII-Redaction am Ingress, Retention â‰¤30 Tage

â¸»

7) Performance-Playbook
	â€¢	Frontend: Route-Level Code-Split, Critical-CSS, lokale Fonts, Icon-Sprites, MapLibre Style-Pruning
	â€¢	API: fetch-first, minimal Middleware, JSON-Streaming
	â€¢	DB: ST_DWithin + GiST, BBOX-Vorfiltro, Hot-Queries als MatViews (FAST-Refresh)
	â€¢	Events: Dedup-Keys, Exponential Backoff, DLQ-Dashboards + Replay
	â€¢	Tiles: Ab hoher Punktdichte â†’ MVT; kleine Daten â†’ FlatGeobuf

Budgets: Start-JS â‰¤70 KB; API p95 â‰¤150 ms; DB p95 â‰¤50 ms; Outbox-Lag <1 s; CLS <0,1

â¸»

8) Upgrade-/Fallback-Pfade
	â€¢	Geo-Power: Martin/Tegola aktivieren â†’ MapLibre auf MVT
	â€¢	Geo/ML: optional Django-Micro
	â€¢	Edge: Hono-Adapter fÃ¼r spÃ¤tere Edge-Routen (Workers etc.)
	â€¢	Vendor-Switch: Caddy/Compose/Volumes portabel; Postgres ggf. managed

â¸»

9) Governance-MVP

Kernobjekte & Verfahren (Garnrollen, FÃ¤den, Garn, Delegationen, 7+7-Modell, RoN) sind Roadmap-Bestandteil, bleiben stack-entkoppelt und werden Ã¼ber Contracts versioniert ï¿¼ ï¿¼.

â¸»

10) Fazit

Optimaler Kern: Bun/Elysia + SvelteKit + MapLibre + NATS + Postgres/PostGIS + Drizzle + Zitadel + Prom/Loki/Grafana + Caddy.
Optionale Booster: Martin/Tegola (MVT), Django-Micro (Geo/ML).

Warum: schnell, gÃ¼nstig, mobil-stark, mit klaren Evolutionspfaden â€“ ohne Lock-in.

â¸»

âˆ´essenz.kernÎ£
Leicht, schnell, modular â€“ VertrÃ¤ge im Zentrum, Events im Fluss, Geo direkt aus PostGIS. Alles Weitere nur optional.

---

```

### ğŸ“„ docs/wg.md

**GrÃ¶ÃŸe:** 592.00 B

```markdown

## Reload mit `--here`
`wg reload [1|2] --here` startet die neue Shell **genau im aktuellen Unterordner** (falls dieser innerhalb des Repos liegt), sonst im Repo-Root.
- `1` = Bash neu
- `2` = Termux: Debian-Proot (Bun) im Ziel

## Heal
`wg heal` hilft bei divergenten Branches:
- **1** lokal bevorzugen â†’ `git pull -s recursive -X ours`
- **2** remote bevorzugen â†’ `git pull -s recursive -X theirs`
- **3** Rebase â†’ `git pull --rebase`
- **4** Fast-Forward only â†’ `git pull --ff-only`

Vorher wird ein Stash angelegt (falls der Arbeitsbaum dirty ist) und danach wieder eingespielt.
```

### ğŸ“„ docs/zusammenstellung.md

**GrÃ¶ÃŸe:** 9.83 KB

```markdown
# Zusammenstellung (MANDATORISCH)

Das Weltgewebe: Eine Systematische Zusammenfassung

Das Weltgewebe ist eine kartenbasierte soziale Infrastruktur, die als eine Art Demokratie-Engine auf einer interaktiven Karte konzipiert ist. Jeder Beitrag eines Nutzers wird als "Faden" visualisiert. Die Plattform basiert auf den Kernprinzipien der radikalen Transparenz, Freiwilligkeit, technischer Absicherung durch Event-Sourcing und einem integrierten Datenschutzkonzept.

I. Grundprinzipien und Philosophie

- Alles ist ein Event: Jede Aktion im System wird als ein unverÃ¤nderliches, signiertes Ereignis in einer Hash-Kette gespeichert (Event-Sourcing).
- Radikale Transparenz: GrundsÃ¤tzlich sind alle Aktionen Ã¶ffentlich sichtbar. Ausgenommen sind private Informationen im Nutzerkonto und private Nachrichten zwischen Nutzern.
- Freiwilligkeit: Die Teilnahme am Weltgewebe erfolgt ausschlieÃŸlich nach informierter Zustimmung.
- Datenschutz (Privacy by Design): Es findet keine verdeckte Datensammlung statt, also keine Cookies, kein Tracking und keine automatische Profilbildung. Sichtbar ist nur, was Nutzer bewusst eintragen, wie Name, Wohnort und Verbindungen. Die rechtliche Grundlage fÃ¼r die Datenverarbeitung bilden die Datenschutzgrundverordnung-Artikel 6 Abs. 1 lit. a und f.
- WÃ¤hrungskonzept: Es gibt keine kÃ¼nstlichen Credits oder AlternativwÃ¤hrungen. Die eigentliche "WÃ¤hrung" ist sichtbares Engagement in Form von FÃ¤den und Garn sowie die von Nutzern eingebrachten Ressourcen. Spenden kÃ¶nnen zusÃ¤tzlich Ã¼ber "GoldfÃ¤den" sichtbar gemacht werden.

II. Das DomÃ¤nenmodell: Nutzer, Inhalte und Struktur
Nutzer (Garnrollen)

- Nutzeraccounts (Rollen): Nutzer werden als "Garnrollen"-Icon an ihrem Wohnort auf der Karte visualisiert. Jede Aktion fÃ¼hrt dazu, dass sich diese Rolle fÃ¼r alle sichtbar dreht.
- Verifizierung: Accounts werden von Verantwortlichen einer lokalen "Ortsweberei" durch eine IdentitÃ¤tsprÃ¼fung verifiziert und erstellt.
- Profilbereiche: Jeder Account verfÃ¼gt Ã¼ber einen privaten Bereich fÃ¼r Kontoinformationen und einen Ã¶ffentlichen Raum. Im Ã¶ffentlichen Bereich kÃ¶nnen Nutzer Informationen Ã¼ber sich selbst sowie GÃ¼ter und Kompetenzen eintragen, die sie der Gemeinschaft zur VerfÃ¼gung stellen mÃ¶chten.
  Inhalte (Knoten, FÃ¤den, Garn)
- Knoten: Dies sind ortsbezogene BÃ¼ndel von Informationen, wie Ideen, Veranstaltungen, Ressourcen, Werkzeuge oder SchlafplÃ¤tze. Jeder Knoten erÃ¶ffnet einen eigenen Raum, der Threads, Informationen und AntrÃ¤ge enthalten kann. Informationen kÃ¶nnen alternativ auch direkt auf der eigenen Garnrolle verortet werden. Knoten sind auf der Karte filter- und einblendbar.
- FÃ¤den: Jede Nutzeraktion erzeugt einen "Faden" von der Garnrolle des Nutzers zu einem Knoten. Es gibt verschiedene Faden-Typen, darunter GesprÃ¤chs-, Gestaltungs-, Ã„nderungs-, Antrags-, Abstimmungs-, Gold-, Melde- und DelegationsfÃ¤den. DelegationsfÃ¤den verlaufen von einer Garnrolle zu einer anderen. Nebeneinanderliegende FÃ¤den und Garne, die von einer Rolle zu einem Knoten fÃ¼hren, Ã¼berlappen sich zunehmend, um zu dicke Linien zu vermeiden.
- VergÃ¤nglichkeit und BestÃ¤ndigkeit (Garn): FÃ¤den verblassen sukzessive innerhalb von 7 Tagen, wenn sie nicht durch einen Klick auf den "Verzwirnungsbutton" zu "Garn" gemacht werden. Verzwirnte FÃ¤den (Garn) sind dauerhaft und schÃ¼tzen Inhalte sowie den gesamten Knoten vor VerÃ¤nderung und AuflÃ¶sung.
  Strukturknoten
  Dies sind permanente und immer sichtbare Knoten fÃ¼r zentrale Funktionen:
- Gewebekonto: Dient der Finanzverwaltung und der Ãœbersicht Ã¼ber GoldfÃ¤den.
- Webrat: Der Ort fÃ¼r Governance, AntrÃ¤ge und die Ãœbersicht Ã¼ber Delegationen. Alle Abstimmungen sind hier ebenso einsehbar und man kann daran teilnehmen.
- NÃ¤hstÃ¼bchen: Ein ortsunabhÃ¤ngiger Raum fÃ¼r die allgemeine Kommunikation.
- RoN-Platzhalter: Ein spezieller Knoten, an dem anonymisierte Inhalte nach 84 Tagen gesammelt werden.

III. Zeitlichkeit, Sichtbarkeit und Anonymisierung

- 7-Sekunden-Rotation: Nach jeder Aktion dreht sich die Garnrolle des Nutzers fÃ¼r 7 Sekunden sichtbar auf der Karte.
- 7-Tage-Verblassen: FÃ¤den, die nicht zu Garn verzwirnt werden, verblassen innerhalb von 7 Tagen sukzessive. Knoten, zu denen 7 Tage lang kein neuer Faden fÃ¼hrt, lÃ¶sen sich ebenfalls in diesem Zeitraum sukzessive auf.
- Anonymisierung (RoN-System):
  - Nutzer kÃ¶nnen per Opt-in festlegen, dass ihre BeitrÃ¤ge nach x Tagen automatisch anonymisiert werden. Der Autorenname wird dann durch "RoN" (Rolle ohne Namen) ersetzt.
  - Die anonymisierten FÃ¤den fÃ¼hren dann nicht mehr zur ursprÃ¼nglichen Garnrolle, sondern zum zentralen RoN-Platzhalter. Das Wissen bleibt so im Gewebe erhalten.
- Ausstiegsprozess: Wenn ein Nutzer die Plattform verlÃ¤sst, durchlaufen alle seine Daten den RoN-Prozess. BeitrÃ¤ge, die jÃ¼nger als x Tage sind, bleiben so lange namentlich sichtbar, bis diese Frist erreicht ist. Am Ende wird die Garnrolle des Nutzers gelÃ¶scht.
- Eigene BeitrÃ¤ge und Aktionen kÃ¶nnen selbstverstÃ¤ndlich jederzeit gelÃ¶scht werden

IV. Governance und Demokratische Prozesse

- 7+7-Modell fÃ¼r AntrÃ¤ge:
  - Ein gestellter Antrag wird mit einem 7-Tage-Timer sichtbar.
  - Erfolgt innerhalb dieser Frist kein Einspruch, wird der Antrag automatisch angenommen.
  - Bei einem Einspruch beginnt eine weitere 7-tÃ¤gige Abstimmungsphase, in der eine einfache Mehrheit entscheidet. Abstimmungen sind Ã¶ffentlich und namentlich einsehbar, optional mit BegrÃ¼ndung.
- Delegation (Liquid Democracy): Nutzer kÃ¶nnen ihre Stimme 1:1 an einen anderen Nutzer Ã¼bertragen. Diese Delegationen werden als gestrichelte Pfeile zwischen den Garnrollen visualisiert und verfallen nach 4 Wochen InaktivitÃ¤t des Delegierenden. FÃ¼r eine spÃ¤tere Phase (B) ist eine transitive Delegation mit Zykluserkennung (Cycle-Detection) geplant. Eine direkte Stimmabgabe Ã¼berschreibt dabei temporÃ¤r die Delegation. Rollen, die Delegationen empfangen haben, zeigen deren Gewicht an.
- Moderation ("Legal Freeze"): Strafbare Inhalte kÃ¶nnen Ã¼ber einen "Melden"-Button gemeldet werden, was ebenfalls einen Faden erzeugt. Bei Verdacht auf eine Straftat erfolgt ein sofortiger Freeze mit gerichtsfester Beweissicherung. Der gemeldete Inhalt wird fÃ¼r 24 Stunden eingeklappt und im Webrat sowie am Ort des Inhalts zur Abstimmung gestellt. Eine einfache Mehrheit entscheidet Ã¼ber die weitere Vorgehensweise. Eine Entfernung erfolgt nur, wo es rechtlich geboten ist, und nach Abschluss des Verfahrens wird ein Ã¶ffentlicher Folge-Antrag gestellt.
- Politischer Arm (Partizipartei): Jede Ortsweberei kann einen politischen Arm grÃ¼nden, die "Partizipartei". MandatstrÃ¤ger ("FadentrÃ¤ger") und ihre Helfer ("Fadenreicher") arbeiten unter permanenter Live-Ãœbertragung. Die BÃ¼rgerbeteiligung wird durch einen Chat mit Aufwertung/Abwertung und optionaler KÃ¼nstliche Intelligenz-UnterstÃ¼tzung ermÃ¶glicht. Jede Funktion und jeder Posten kann per Antrag verÃ¤ndert oder abgewÃ¤hlt werden.

V. BenutzeroberflÃ¤che und Nutzererlebnis

- Karten-Interface: Die primÃ¤re OberflÃ¤che ist eine Vollbildkarte (MapLibre GL).
- Drawer-System:
  - Links: Zugriff auf Webrat und NÃ¤hstÃ¼bchen (Governance und Kommunikation).
  - Rechts: Filter fÃ¼r Knoten- und Fadenarten, ein Zeitfenster und ein SuchmenÃ¼.
- Suchfunktion: Ãœber das SuchmenÃ¼ kÃ¶nnen die von Nutzern zur VerfÃ¼gung gestellten GÃ¼ter und Kompetenzen abgefragt werden. Treffer werden als aufleuchtende Rollen oder Knoten auf der Karte sowie in einer nach Entfernung sortierten Liste angezeigt. Ein Klick auf einen Listeneintrag zentriert die Karte auf den entsprechenden Nutzer.
- Widgets: Oben mittig befindet sich das Gewebekonto-Widget (Saldo, Bewegungen), oben rechts der Zugang zum eigenen Konto und zur Verifikation.
- Zeitleiste: Eine Zeitachse am unteren Bildschirmrand ermÃ¶glicht die RÃ¼ckschau auf vergangene AktivitÃ¤ten ("Webungen").

VI. Organisation und Technische Architektur

- Lokale Organisation (Ortswebereien): Das Weltgewebe wird durch lokale "Ortswebereien" konkret umgesetzt. Jede dieser Gruppen verfÃ¼gt Ã¼ber ein eigenes Gemeinschaftskonto (Gewebekonto) und eine Unterseite auf weltgewebe.net. FÃ¶derationen von Ortswebereien sind vorgesehen.
- Technischer Stack und Verortung: Die Architektur basiert auf Event-Sourcing mit NATS JetStream, PostgreSQL/PostGIS und Redis. Knoten und Rollen werden H3-basiert gespeichert, um rÃ¤umliche Abfragen, Filter und Indizes zu ermÃ¶glichen.
- Hosting und Betrieb:
  - Der Betrieb ist fÃ¼r ein kleines Team (1â€“2 Personen) durch Automatisierung (Cronjobs, Healthchecks) ausgelegt.
  - Das Hosting erfolgt primÃ¤r bei Hetzner, um Kosteneffizienz und Datenschutzgrundverordnung-KonformitÃ¤t zu gewÃ¤hrleisten ("Hetzner-First").
- Performance ("Mobile-First"): Die Plattform ist fÃ¼r Smartphones optimiert. Angestrebt werden ein Initial-Bundle von â‰¤ 90 KB und eine Time-to-Interactive von unter 2,5 Sekunden auf einer 3G-Verbindung. Weitere Performance-Ziele sind P95 API-Antwortzeiten von â‰¤ 300 ms und P95 Datenbankabfragen von â‰¤ 150 ms.
- Skalierung und Kosten: Ein Phasenmodell sichert die Skalierbarkeit von einem Single-Server (unter 200 â‚¬/Monat) bis hin zu Multi-Region-Clustern. Ziel ist es, die Kosten pro 1.000 Events unter 0,01 â‚¬ zu halten.
- Hybrid-Indexierung: Live-Routen (z.B. /map, /feed) senden den X-Robots-Tag noindex, noarchive. Monatsarchive (z.B. /archive/YYYY-MM) sind hingegen als index, follow markiert und setzen ein rel="canonical"-Tag, um die Nachvollziehbarkeit zu gewÃ¤hrleisten.
- Monitoring, Alarme und BetriebsplÃ¤ne:
  - Metriken: Es werden Governance-Metriken (z.B. Teilnahmequote), RoN-Metriken (z.B. Transferrate) und Kosten-Metriken (z.B. â‚¬/aktiver Nutzer) Ã¼berwacht. Es gibt Alarm-Regeln, z.B. bei Latenzen Ã¼ber 1000 ms oder wenn die Kosten in Phase A 200 â‚¬ Ã¼bersteigen.
  - BetriebsplÃ¤ne (Cronjobs): Governance-Timer laufen minÃ¼tlich; Delegations-PrÃ¼fungen tÃ¤glich um 01:00 Uhr; RoN-Prozesse um 02:00 Uhr und Kosten-Analysen um 03:00 Uhr. FÃ¼r die Systemgesundheit gibt es die Endpunkte /health/live und /health/ready.
```

### ğŸ“„ e --continue

**GrÃ¶ÃŸe:** 1.51 KB

```
* [33m8ff8384[m[33m ([m[1;36mHEAD[m[33m -> [m[1;32mmain[m[33m)[m ci: Actions-Workflow (Bun/Elysia, Coverage-Gate, k6-Smoke)
[31m|[m * [33m385a6b0[m[33m ([m[1;31morigin/main[m[33m, [m[1;31morigin/HEAD[m[33m)[m wg: commit via Codespace 2025-09-06 18:47:09 UTC
[31m|[m[31m/[m  
* [33m8a5df35[m wg: mobile push 2025-09-06 18:32:22 UTC
* [33m4cf33e3[m wg: mobile push 2025-09-06 18:01:22 UTC
* [33m6d09685[m wg send: main 2025-09-06 19:09:36
* [33m94ca385[m wg send: main 2025-09-06 19:06:44
* [33me9b5ba5[m wg send: main 2025-09-06 19:06:03
* [33m8994457[m Update: zusammenstellung.md, inhalt.md, fahrplan.md, webstack.md
* [33m9cc6f10[m fix(devcontainer): Safe-Mode (keine externen Downloads, defensive postCreate/Start)
* [33mf43ab34[m fix(devcontainer): remove DinD feature for Codespaces; dedupe README hint
* [33m55f2050[m fix(devcontainer): remove root Dockerfile, enforce .devcontainer/Dockerfile
* [33ma73c681[m fix(devcontainer): remove root Dockerfile, enforce .devcontainer/Dockerfile
* [33m001c6f2[m let's roll
*   [33m7f516ea[m Merge branch 'main' of git@github.com:weltgewebe/weltgewebe-repo.git
[33m|[m[34m\[m  
[33m|[m * [33ma27d92e[m - old devcontainer
* [34m|[m [33m632c5d5[m Merge branch 'main' of git@github.com:weltgewebe/weltgewebe-repo.git
[35m|[m[34m\[m[34m|[m 
[35m|[m * [33m4a7c73a[m devcontainer
* [36m|[m [33m1ca1dfa[m nun aber
* [36m|[m [33m1216ce0[m neue webstack.md
* [36m|[m [33m321e664[m Create webstack.md
[36m|[m[36m/[m  
```

### ğŸ“„ package.json

**GrÃ¶ÃŸe:** 800.00 B

```json
{
  "name": "weltgewebe",
  "private": true,
  "packageManager": "bun@1.2.21",
  "workspaces": ["apps/*", "packages/*"],
  "engines": { "node": ">=20" },
  "scripts": {
    "dev:web": "bun --cwd apps/web run dev",
    "dev:api": "bun --cwd apps/api-elysia run dev",
    "dev": "concurrently -k -n web,api \"bun run dev:web\" \"bun run dev:api\"",
    "typecheck": "bun --cwd apps/api-elysia run check",
    "build": "bun --cwd apps/api-elysia run build",
    "infra:up": "docker compose -f infra/compose.yml up -d",
    "infra:down": "docker compose -f infra/compose.yml down -v",
    "infra:logs": "docker compose -f infra/compose.yml logs -f --tail=50"
  },
  "devDependencies": {
    "concurrently": "^9.0.1",
    "@biomejs/biome": "^1.9.4",
    "typescript": "^5.6.2",
    "zod": "^3.23.8"
  }
}
```

### ğŸ“„ packages/contracts/package.json

**GrÃ¶ÃŸe:** 172.00 B

```json
{
  "name": "@welt/contracts",
  "version": "1.0.0",
  "type": "module",
  "exports": "./src/index.ts",
  "devDependencies": { "zod": "^3.23.8", "typescript": "^5.6.2" }
}
```

### ğŸ“„ packages/contracts/src/index.ts

**GrÃ¶ÃŸe:** 410.00 B

```typescript
import { z } from "zod";

export const WGUserId = z.string().uuid();
export const WGRole = z.enum(["viewer","member","moderator","admin"]);

export const AuthClaims = z.object({
  sub: WGUserId,
  roles: z.array(WGRole).default(["viewer"]),
  iat: z.number(),
  exp: z.number()
});

export const EchoBody = z.object({
  message: z.string().min(1).max(200)
});
export type TEchoBody = z.infer<typeof EchoBody>;
```

### ğŸ“„ packages/core/package.json

**GrÃ¶ÃŸe:** 149.00 B

```json
{
  "name": "@welt/core",
  "version": "1.0.0",
  "type": "module",
  "exports": "./src/index.ts",
  "devDependencies": { "typescript": "^5.6.2" }
}
```

### ğŸ“„ packages/core/src/index.ts

**GrÃ¶ÃŸe:** 134.00 B

```typescript
export const ok = <T>(data: T) => ({ ok: true as const, data });
export const err = <E>(error: E) => ({ ok: false as const, error });
```

### ğŸ“„ README.md

**GrÃ¶ÃŸe:** 142.00 B

```markdown
# Weltgewebe â€“ Monorepo (Bootstrap)
Leicht, schnell, modular: SvelteKit + Bun/Elysia + Postgres/PostGIS + NATS + Caddy + Prom/Loki/Grafana.
```

### ğŸ“„ scripts/codex-run.sh

**GrÃ¶ÃŸe:** 1.44 KB

```bash
#!/usr/bin/env bash
set -euo pipefail

export BUN_INSTALL="${BUN_INSTALL:-$HOME/.bun}"
export PATH="$BUN_INSTALL/bin:$PATH"
export NODE_ENV="${NODE_ENV:-production}"
export CI="${CI:-true}"

echo "â–¶ Install..."
bun install --frozen-lockfile
bun install -C apps/web || true
bun install -C apps/api-elysia || true

echo "â–¶ Typecheck..."
bunx tsc -p apps/web/tsconfig.json --noEmit
bunx tsc -p apps/api-elysia/tsconfig.json --noEmit

echo "â–¶ Lint..."
if [ -f biome.json ] || [ -f .biome.json ]; then
  bunx biome ci .
else
  echo "â„¹ï¸ Biome-Konfig nicht gefunden â€“ Lint wird ausgelassen."
fi

echo "â–¶ Tests..."
bun test --coverage

echo "â–¶ Build smoke..."
bun run -C apps/web build
# falls api-elysia kein build-script hat, fÃ¤llt es auf Typecheck zurÃ¼ck
if bun run -C apps/api-elysia build 2>/dev/null; then
  echo "API build ok"
else
  echo "API build-script fehlt â€“ mache Typecheck als Smoke."
  bunx tsc -p apps/api-elysia/tsconfig.json --noEmit
fi

# Optional: Budgets & Smoke gegen laufende Services
if [ "${RUN_BUDGETS:-0}" = "1" ]; then
  echo "â–¶ Lighthouse Budgets (mobil)..."
  bash scripts/lighthouse/lhci-mobile.sh || (echo "âš ï¸ LHCI Warnung" && exit 1)
fi

if [ "${RUN_K6:-0}" = "1" ]; then
  echo "â–¶ k6 Smoke..."
  if command -v k6 >/dev/null 2>&1; then
    k6 run scripts/k6/smoke.js
  else
    echo "âš ï¸ k6 nicht installiert â€“ Smoke wird Ã¼bersprungen (RUN_K6=0 setzen, oder k6 installieren)."
  fi
fi

echo "âœ… Codex-Run fertig."
```

### ğŸ“„ scripts/k6/smoke.js

**GrÃ¶ÃŸe:** 608.00 B

```javascript
import http from "k6/http";
import { check, sleep } from "k6";

export const options = {
  vus: 10,
  duration: "10s",
  thresholds: {
    http_req_failed: ["rate<0.01"],
    http_req_duration: ["p(95)<300"], // p95 < 300ms
  },
};

const BASE = __ENV.API_BASE || "http://localhost:8787";

export default function () {
  let res1 = http.get(`${BASE}/health`);
  check(res1, { "health 200": (r) => r.status === 200 });

  let res2 = http.get(`${BASE}/metrics`);
  check(res2, {
    "metrics 200": (r) => r.status === 200,
    "wg_up present": (r) => r.body && r.body.includes("wg_up"),
  });

  sleep(0.2);
}
```

### ğŸ“„ scripts/lighthouse/budgets.json

**GrÃ¶ÃŸe:** 218.00 B

```json
[
  {
    "path": "/*",
    "resourceSizes": [
      { "resourceType": "script", "budget": 70 }   // KB Start-JS
    ],
    "timings": [
      { "metric": "largest-contentful-paint", "budget": 1800 } // ms
    ]
  }
]
```

### ğŸ“„ scripts/lighthouse/lhci-mobile.sh

**GrÃ¶ÃŸe:** 607.00 B

```bash
#!/usr/bin/env bash
set -euo pipefail

export BUN_INSTALL="${BUN_INSTALL:-$HOME/.bun}"
export PATH="$BUN_INSTALL/bin:$PATH"

# Web-Preview starten (SvelteKit preview; Port 4173 Default)
# Wir bauen NICHT neu â€“ Build ist bereits in codex-run erledigt.
bunx @lhci/cli autorun \
  --collect.startServerCommand="bun run -C apps/web preview --host --port 4173" \
  --collect.url="http://localhost:4173/" \
  --collect.numberOfRuns=1 \
  --collect.settings.preset=mobile \
  --collect.budgetsFile=scripts/lighthouse/budgets.json \
  --assert.preset="lighthouse:recommended" \
  --upload.target=temporary-public
```

### ğŸ“„ wg

**GrÃ¶ÃŸe:** 8.73 KB

```
#!/usr/bin/env bash
# wg â€“ Weltgewebe CLI (PR-only, clean/heal/pr/reload/send)
# mobile-first â€¢ Termux-tolerant â€¢ Codespaces-ready

# ---------- Basics ----------
repo_default="$(cd "$(dirname "$0")" && pwd)"
repo_detected="$(git -C "$PWD" rev-parse --show-toplevel 2>/dev/null)"
repo="${repo_detected:-$repo_default}"

is_termux=0; case "$PREFIX" in */com.termux/*) is_termux=1 ;; esac
log(){ printf "%s\n" "$*"; }
die(){ printf "âŒ %s\n" "$*" >&2; exit 1; }
ensure_repo(){ [ -d "$repo/.git" ] || die "Repo nicht gefunden: $repo"; }

# ---------- Helpers ----------
preflight(){
  cd "$repo" || exit 1
  # blockiere laufende Aktionen
  [ -d .git/rebase-apply ] || [ -d .git/rebase-merge ] && die "Rebase lÃ¤uft (git rebase --continue | --abort)"
  [ -f .git/MERGE_HEAD ] && die "Merge lÃ¤uft (Konflikte lÃ¶sen + commit oder git merge --abort)"
  BRANCH="$(git rev-parse --abbrev-ref HEAD)"; [ "$BRANCH" = "HEAD" ] && die "Detached HEAD"
  UPSTREAM="$(git rev-parse --abbrev-ref --symbolic-full-name @{u} 2>/dev/null || true)"
  if [ -z "$UPSTREAM" ]; then
    if git show-ref --verify --quiet "refs/remotes/origin/$BRANCH"; then
      git branch --set-upstream-to "origin/$BRANCH" "$BRANCH" >/dev/null
      UPSTREAM="origin/$BRANCH"
    else
      UPSTREAM="origin/$BRANCH" # wird beim ersten Push angelegt
    fi
  fi
}

repo_path(){ # nur GitHub-URLs
  local u; u="$(git config --get remote.origin.url 2>/dev/null || true)"
  case "$u" in
    git@github.com:*) printf "%s" "${u#git@github.com:}" | sed "s/\.git$//" ;;
    https://github.com/*) printf "%s" "${u#https://github.com/}" | sed "s/\.git$//" ;;
    *) printf "" ;;
  esac
}

urlencode(){
  # bevorzugt python3, fallback: naive %20 etc.
  if command -v python3 >/dev/null 2>&1; then
    python3 - <<PY 2>/dev/null
import sys, urllib.parse
print(urllib.parse.quote(sys.stdin.read().strip()))
PY
  else
    sed -e "s/%/%25/g" -e "s/ /%20/g" -e "s/\"/%22/g" -e "s/#/%23/g" -e "s/&/%26/g"
  fi
}

auto_title(){
  local branch date last prefix changes
  branch="$(git rev-parse --abbrev-ref HEAD)"
  date="$(date +%Y-%m-%d)"
  last="$(git log -1 --pretty="%s" 2>/dev/null || echo "update")"
  prefix="feat"
  if [[ "$last" =~ ^(feat|fix|chore|docs|refactor|perf|test) ]]; then prefix="${BASH_REMATCH[1]}"; fi
  if git rev-parse --verify -q "refs/remotes/origin/$branch" >/dev/null 2>&1; then
    changes="$(git diff --name-only "origin/$branch"... 2>/dev/null | wc -l | awk "{print \$1}")"
  else
    changes="0"
  fi
  printf "%s: %s | %s | %s (%s changes)" "$prefix" "$branch" "$date" "$last" "$changes"
}

# ---------- Commands ----------
cmd_go(){
  ensure_repo
  log "ğŸŒ Repo: $repo"
  (cd "$repo" && ls -1 . 1>/dev/null) && log "âœ… erreichbar"
}

cmd_doctor(){
  ensure_repo
  log "ğŸ©º $(git --version 2>/dev/null || echo git fehlt)"
  command -v curl >/dev/null 2>&1 && log "âœ… curl: $(curl --version | head -n1)" || log "â„¹ï¸ curl nicht gefunden (ok)"
  [ "$is_termux" -eq 1 ] && command -v proot-distro >/dev/null 2>&1 && log "âœ… proot-distro" || true
}

# Vorschau: wg clean | Anwenden: wg clean --apply
cmd_clean(){
  ensure_repo; cd "$repo" || exit 1
  local apply=0; case "$1" in --apply|-y|--force) apply=1;; esac
  mapfile -t HITS < <(find . -path "./.git" -prune -o \( \
     -type f \( -name "*.bak" -o -name "*.tmp" -o -name "*.orig" -o -name "*.rej" -o -name "*~" -o -name ".DS_Store" -o -name "Thumbs.db" -o -name "*.swp" \) -o \
     -type d \( -name "node_modules" -o -name "dist" -o -name ".svelte-kit" -o -name "coverage" \) \
   \) -print 2>/dev/null)
  [ ${#HITS[@]} -eq 0 ] && { log "âœ… Nichts zu sÃ¤ubern."; return 0; }
  if [ $apply -eq 0 ]; then
    log "ğŸ‘€ Vorschau (nichts gelÃ¶scht). Anwenden: wg clean --apply"
    printf "%s\n" "${HITS[@]}"
  else
    log "ğŸ—‘ï¸  LÃ¶sche ${#HITS[@]} EintrÃ¤geâ€¦"
    printf "%s\n" "${HITS[@]}" | awk "{print length, \$0}" | sort -nr | cut -d" " -f2- | while read -r p; do
      [ -d "$p" ] && rm -rf -- "$p" || rm -f -- "$p"
    done
    log "âœ… Clean fertig."
  fi
}

# Interaktiver Konflikt-Heiler
cmd_heal(){
  ensure_repo; preflight
  cd "$repo" || return 1
  echo "ğŸ§© Strategie wÃ¤hlen:"
  echo "  1) lokal bevorzugen  (merge -X ours)"
  echo "  2) remote bevorzugen (merge -X theirs)"
  echo "  3) rebase"
  echo "  4) fast-forward only"
  read -p "â¤ Auswahl [1/2/3/4]: " sel
  case "$sel" in
    1) git pull -s recursive -X ours ;;
    2) git pull -s recursive -X theirs ;;
    3) git pull --rebase ;;
    4) git pull --ff-only ;;
    *) log "Abbruch."; return 1 ;;
  esac || { log "âš ï¸ Konflikte/Fehler. Bitte manuell lÃ¶sen."; return 1; }
  log "âœ… Heal erfolgreich."
}

# PR-Link erzeugen (mit Auto-Titel)
cmd_pr(){
  ensure_repo; preflight
  cd "$repo" || exit 1
  local title="${*}"; [ -z "$title" ] && title="$(auto_title)"
  local path; path="$(repo_path)"
  [ -z "$path" ] && { log "â„¹ï¸ PR-Link nicht ableitbar (Remote nicht GitHub)"; return 0; }
  local enc; enc="$(printf "%s" "$title" | urlencode)"
  local head; head="$(git rev-parse --abbrev-ref HEAD)"
  printf "ğŸ”— PR-Link: https://github.com/%s/compare/main...%s?expand=1&title=%s\n" "$path" "$head" "$enc"
}

# PR-only Flow: nie direkt auf main
cmd_send(){
  ensure_repo; preflight
  cd "$repo" || exit 1

  # Nie direkt auf main arbeiten â†’ Branch anlegen
  if [ "$BRANCH" = "main" ]; then
    local ts; ts="$(date -u +%Y%m%d-%H%M%S)"
    local newb="pr/feat-${ts}"
    log "âš ï¸ Du bist auf main â†’ erzeuge Feature-Branch: $newb"
    git checkout -b "$newb"
    BRANCH="$newb"; UPSTREAM="origin/$BRANCH"
  fi

  # add/commit (Auto-Message)
  git add -A
  if git diff --staged --quiet; then
    log "â„¹ï¸ Keine neuen Ã„nderungen zu committen."
  else
    local msg; msg="wg: mobile push $(date -u "+%Y-%m-%d %H:%M:%S UTC") on ${BRANCH}"
    git commit -m "$msg" || die "Commit fehlgeschlagen"
    log "âœ… Commit: $msg"
  fi

  # rebase-pull â†’ bei Konflikt interaktiv entscheiden
  log "ğŸ”„ Pull --rebase â€¦"
  if ! git pull --rebase -s recursive -X ours; then
    echo "âš ï¸ Rebase-Konflikt. Optionen:"
    echo "   1) lokal bevorzugen  (-X ours)"
    echo "   2) remote bevorzugen (-X theirs)"
    echo "   3) rebase neu versuchen"
    echo "   4) ff-only versuchen"
    echo "   5) abbrechen"
    read -p "â¤ Auswahl [1/2/3/4/5]: " sel
    case "$sel" in
      1) git rebase --abort >/dev/null 2>&1 || true; git pull -s recursive -X ours   || die "fehlgeschlagen" ;;
      2) git rebase --abort >/dev/null 2>&1 || true; git pull -s recursive -X theirs || die "fehlgeschlagen" ;;
      3) git rebase --continue 2>/dev/null || { git rebase --abort >/dev/null 2>&1 || true; git pull --rebase || die "fehlgeschlagen"; } ;;
      4) git rebase --abort >/dev/null 2>&1 || true; git pull --ff-only || die "nicht mÃ¶glich" ;;
      5) log "Abbruch."; return 1 ;;
      *) log "Abbruch."; return 1 ;;
    esac
  fi

  # push
  if git rev-parse --verify -q "refs/remotes/origin/$BRANCH" >/dev/null 2>&1; then
    git push origin "$BRANCH" || die "Push fehlgeschlagen"
  else
    git push -u origin "$BRANCH" || die "Push fehlgeschlagen"
  fi
  log "ğŸš€ Branch gepusht: origin/$BRANCH"

  # PR-Link ausgeben (Auto-Titel)
  cmd_pr
}

# 1 = Bash neu, 2 = Debian-Proot (Bun) â€“ mit --here
cmd_reload(){
  ensure_repo
  local mode="" keep_here=0
  while [ $# -gt 0 ]; do case "$1" in 1|2) mode="$1";; --here|-H) keep_here=1;; esac; shift; done
  local repo_abs cur_abs target
  repo_abs="$(cd "$repo" 2>/dev/null && pwd -P || echo "$repo")"
  cur_abs="$(pwd -P 2>/dev/null || pwd)"
  if [ $keep_here -eq 1 ] && [ "${cur_abs#"$repo_abs"/}" != "$cur_abs" ]; then target="$cur_abs"; else target="$repo_abs"; fi

  if [ -z "$mode" ]; then
    echo "ğŸ”„ Shell neuâ€¦ (Ziel: $target)"
    echo "  1) Bash"
    [ "$is_termux" -eq 1 ] && echo "  2) Debian-Proot (Bun)"
    read -p "â¤ Eingabe [1$([ "$is_termux" -eq 1 ] && echo "/2")]: " mode
  fi

  case "$mode" in
    2)
      if [ "$is_termux" -eq 1 ]; then
        echo "ğŸš€ Debian-Proot in: $target"
        exec proot-distro login debian -- bash -lc "cd \"$target\" || cd ~; exec bash -l"
      else
        echo "â„¹ï¸ Option 2 nur auf Termux sinnvoll. Starte normale Shell."
        exec bash -l
      fi
      ;;
    *)
      echo "ğŸš€ Bash in: $target"
      exec bash -lc "cd \"$target\" || cd ~; exec bash -l"
      ;;
  esac
}

usage(){
  cat <<USAGE
âš¡ wg usage:
  wg go | doctor
  wg clean [--apply]
  wg heal
  wg pr [Titel optional]        # PR-Link (Auto-Titel, wenn leer)
  wg send                       # PR-only Flow (nie direkt auf main)
  wg reload [1|2] [--here]      # 1=Bash, 2=Proot/Bun (nur Termux)
USAGE
}

case "$1" in
  go) shift; cmd_go "$@" ;;
  doctor) shift; cmd_doctor "$@" ;;
  clean) shift; cmd_clean "$@" ;;
  heal) shift; cmd_heal "$@" ;;
  pr) shift; cmd_pr "$@" ;;
  send) shift; cmd_send "$@" ;;
  reload) shift; cmd_reload "$@" ;;
  ""|help|-h|--help) usage ;;
  *) echo "Unbekannt: $1"; usage; exit 1 ;;
esac
```

### ğŸ“„ wg.bak.1757191428

**GrÃ¶ÃŸe:** 3.13 KB

```
#!/data/data/com.termux/files/usr/bin/bash
# Weltgewebe CLI (Termux) â€“ interaktiv; KEIN set -e/-u/pipefail

repo="/data/data/com.termux/files/home/weltgewebe-repo"

log(){ printf "%s\n" "$*"; }
ensure_repo(){ [ -d "$repo/.git" ] || { log "âŒ Repo nicht gefunden: $repo"; exit 1; }; }

cmd_go(){
  ensure_repo
  log "ğŸŒ Starte Weltgewebe-Checksâ€¦"
  ( cd "$repo" && ls -1 .codex scripts scripts/k6 scripts/lighthouse 2>/dev/null )
}

cmd_doctor(){
  ensure_repo
  log "ğŸ©º Doctor:"
  command -v git  >/dev/null && log "âœ… git: $(git --version)" || log "âŒ git fehlt"
  command -v curl >/dev/null && log "âœ… curl: $(curl --version | head -n1)" || log "âŒ curl fehlt"
  ( cd "$repo" && log "ğŸ“œ letzte Commits:" && git --no-pager log --oneline -n 5 )
}

cmd_send(){
  ensure_repo
  cd "$repo" || exit 1
  branch="$(git rev-parse --abbrev-ref HEAD 2>/dev/null || echo main)"
  ts="$(date -u "+%Y-%m-%d %H:%M:%S UTC")"
  host="$(termux-info 2>/dev/null | awk -F": " "/Device model/{print \}" | head -n1)"
  msg="wg: mobile push $ts${host:+ [$host]}"
  git add -A
  if git diff --staged --quiet; then
    log "â„¹ï¸  Keine Ã„nderungen zum Commit. Pushe nur."
  else
    git commit -m "$msg" || { log "âŒ Commit fehlgeschlagen"; exit 1; }
  fi
  git push origin "$branch" || { log "âŒ Push fehlgeschlagen"; exit 1; }
  log "âœ… Gesendet auf $branch"
}

cmd_sync(){
  ensure_repo
  cd "$repo" || exit 1
  git fetch origin
  git pull --rebase -s recursive -X ours origin "$(git rev-parse --abbrev-ref HEAD)"
}

cmd_heal(){
  ensure_repo
  cd "$repo" || exit 1
  branch="$(git rev-parse --abbrev-ref HEAD 2>/dev/null || echo main)"
  backup="backup/${branch}-$(date +%Y%m%d-%H%M%S)"
  log "ğŸ›Ÿ Backup-Branch: $backup"
  git branch -c "$backup" || true
  log "â¬‡ï¸  Hole aktuelle Remote-Datenâ€¦"
  git fetch origin
  log "ğŸ”„ Versuche Rebase (lokal bevorzugt)â€¦"
  if git pull --rebase -s recursive -X ours origin "$branch"; then
    log "âœ… Rebase erfolgreich"; return
  fi
  log "âš ï¸ Rebase gescheitert â€“ versuche Merge (ours bevorzugt)â€¦"
  if git merge -s recursive -X ours origin/"$branch"; then
    log "âœ… Merge erfolgreich"; return
  fi
  log "âŒ Automatisches Heilen fehlgeschlagen. Bitte manuell lÃ¶sen."
  exit 1
}

cmd_reload(){
  echo "ğŸ”„ Shell wird neu gestartet..."
  echo "WÃ¤hle Ziel:"
  echo "  1) Termux (Standard)"
  echo "  2) Debian-Proot (fÃ¼r Bun)"
  read -p "â¤ Eingabe [1/2]: " choice
  case "$choice" in
    2) echo "ğŸš€ Starte Debian-Shell..."; exec proot-distro login debian -- bash -l ;;
    *) echo "ğŸš€ Starte Termux-Shell neu..."; exec bash -l ;;
  esac
}

usage(){
  cat <<USAGE
âš¡ wg usage:
  wg go       - schnelle Checks/Startprobe
  wg doctor   - Umgebung prÃ¼fen (git, curl, bun)
  wg send     - add/commit (Auto-Msg) + push
  wg sync     - fetch + pull --rebase (ours)
  wg heal     - Konflikte heilen (Backup â†’ rebase -X ours â†’ merge -X ours)
  wg reload   - Shell neu starten (Termux/Proot)
USAGE
}

case "$1" in
  go)      cmd_go ;;
  doctor)  cmd_doctor ;;
  send)    cmd_send ;;
  sync)    cmd_sync ;;
  heal)    cmd_heal ;;
  reload)  cmd_reload ;;
  ""|help|-h|--help) usage ;;
  *) echo "Unbekannt: $1"; usage; exit 1 ;;
esac
```

### ğŸ“„ wg.bak.1757191456

**GrÃ¶ÃŸe:** 3.13 KB

```
#!/data/data/com.termux/files/usr/bin/bash
# Weltgewebe CLI (Termux) â€“ interaktiv; KEIN set -e/-u/pipefail

repo="/data/data/com.termux/files/home/weltgewebe-repo"

log(){ printf "%s\n" "$*"; }
ensure_repo(){ [ -d "$repo/.git" ] || { log "âŒ Repo nicht gefunden: $repo"; exit 1; }; }

cmd_go(){
  ensure_repo
  log "ğŸŒ Starte Weltgewebe-Checksâ€¦"
  ( cd "$repo" && ls -1 .codex scripts scripts/k6 scripts/lighthouse 2>/dev/null )
}

cmd_doctor(){
  ensure_repo
  log "ğŸ©º Doctor:"
  command -v git  >/dev/null && log "âœ… git: $(git --version)" || log "âŒ git fehlt"
  command -v curl >/dev/null && log "âœ… curl: $(curl --version | head -n1)" || log "âŒ curl fehlt"
  ( cd "$repo" && log "ğŸ“œ letzte Commits:" && git --no-pager log --oneline -n 5 )
}

cmd_send(){
  ensure_repo
  cd "$repo" || exit 1
  branch="$(git rev-parse --abbrev-ref HEAD 2>/dev/null || echo main)"
  ts="$(date -u "+%Y-%m-%d %H:%M:%S UTC")"
  host="$(termux-info 2>/dev/null | awk -F": " "/Device model/{print \}" | head -n1)"
  msg="wg: mobile push $ts${host:+ [$host]}"
  git add -A
  if git diff --staged --quiet; then
    log "â„¹ï¸  Keine Ã„nderungen zum Commit. Pushe nur."
  else
    git commit -m "$msg" || { log "âŒ Commit fehlgeschlagen"; exit 1; }
  fi
  git push origin "$branch" || { log "âŒ Push fehlgeschlagen"; exit 1; }
  log "âœ… Gesendet auf $branch"
}

cmd_sync(){
  ensure_repo
  cd "$repo" || exit 1
  git fetch origin
  git pull --rebase -s recursive -X ours origin "$(git rev-parse --abbrev-ref HEAD)"
}

cmd_heal(){
  ensure_repo
  cd "$repo" || exit 1
  branch="$(git rev-parse --abbrev-ref HEAD 2>/dev/null || echo main)"
  backup="backup/${branch}-$(date +%Y%m%d-%H%M%S)"
  log "ğŸ›Ÿ Backup-Branch: $backup"
  git branch -c "$backup" || true
  log "â¬‡ï¸  Hole aktuelle Remote-Datenâ€¦"
  git fetch origin
  log "ğŸ”„ Versuche Rebase (lokal bevorzugt)â€¦"
  if git pull --rebase -s recursive -X ours origin "$branch"; then
    log "âœ… Rebase erfolgreich"; return
  fi
  log "âš ï¸ Rebase gescheitert â€“ versuche Merge (ours bevorzugt)â€¦"
  if git merge -s recursive -X ours origin/"$branch"; then
    log "âœ… Merge erfolgreich"; return
  fi
  log "âŒ Automatisches Heilen fehlgeschlagen. Bitte manuell lÃ¶sen."
  exit 1
}

cmd_reload(){
  echo "ğŸ”„ Shell wird neu gestartet..."
  echo "WÃ¤hle Ziel:"
  echo "  1) Termux (Standard)"
  echo "  2) Debian-Proot (fÃ¼r Bun)"
  read -p "â¤ Eingabe [1/2]: " choice
  case "$choice" in
    2) echo "ğŸš€ Starte Debian-Shell..."; exec proot-distro login debian -- bash -l ;;
    *) echo "ğŸš€ Starte Termux-Shell neu..."; exec bash -l ;;
  esac
}

usage(){
  cat <<USAGE
âš¡ wg usage:
  wg go       - schnelle Checks/Startprobe
  wg doctor   - Umgebung prÃ¼fen (git, curl, bun)
  wg send     - add/commit (Auto-Msg) + push
  wg sync     - fetch + pull --rebase (ours)
  wg heal     - Konflikte heilen (Backup â†’ rebase -X ours â†’ merge -X ours)
  wg reload   - Shell neu starten (Termux/Proot)
USAGE
}

case "$1" in
  go)      cmd_go ;;
  doctor)  cmd_doctor ;;
  send)    cmd_send ;;
  sync)    cmd_sync ;;
  heal)    cmd_heal ;;
  reload)  cmd_reload ;;
  ""|help|-h|--help) usage ;;
  *) echo "Unbekannt: $1"; usage; exit 1 ;;
esac
```

### ğŸ“„ wg.bak.1757191553

**GrÃ¶ÃŸe:** 3.13 KB

```
#!/data/data/com.termux/files/usr/bin/bash
# Weltgewebe CLI (Termux) â€“ interaktiv; KEIN set -e/-u/pipefail

repo="/data/data/com.termux/files/home/weltgewebe-repo"

log(){ printf "%s\n" "$*"; }
ensure_repo(){ [ -d "$repo/.git" ] || { log "âŒ Repo nicht gefunden: $repo"; exit 1; }; }

cmd_go(){
  ensure_repo
  log "ğŸŒ Starte Weltgewebe-Checksâ€¦"
  ( cd "$repo" && ls -1 .codex scripts scripts/k6 scripts/lighthouse 2>/dev/null )
}

cmd_doctor(){
  ensure_repo
  log "ğŸ©º Doctor:"
  command -v git  >/dev/null && log "âœ… git: $(git --version)" || log "âŒ git fehlt"
  command -v curl >/dev/null && log "âœ… curl: $(curl --version | head -n1)" || log "âŒ curl fehlt"
  ( cd "$repo" && log "ğŸ“œ letzte Commits:" && git --no-pager log --oneline -n 5 )
}

cmd_send(){
  ensure_repo
  cd "$repo" || exit 1
  branch="$(git rev-parse --abbrev-ref HEAD 2>/dev/null || echo main)"
  ts="$(date -u "+%Y-%m-%d %H:%M:%S UTC")"
  host="$(termux-info 2>/dev/null | awk -F": " "/Device model/{print \}" | head -n1)"
  msg="wg: mobile push $ts${host:+ [$host]}"
  git add -A
  if git diff --staged --quiet; then
    log "â„¹ï¸  Keine Ã„nderungen zum Commit. Pushe nur."
  else
    git commit -m "$msg" || { log "âŒ Commit fehlgeschlagen"; exit 1; }
  fi
  git push origin "$branch" || { log "âŒ Push fehlgeschlagen"; exit 1; }
  log "âœ… Gesendet auf $branch"
}

cmd_sync(){
  ensure_repo
  cd "$repo" || exit 1
  git fetch origin
  git pull --rebase -s recursive -X ours origin "$(git rev-parse --abbrev-ref HEAD)"
}

cmd_heal(){
  ensure_repo
  cd "$repo" || exit 1
  branch="$(git rev-parse --abbrev-ref HEAD 2>/dev/null || echo main)"
  backup="backup/${branch}-$(date +%Y%m%d-%H%M%S)"
  log "ğŸ›Ÿ Backup-Branch: $backup"
  git branch -c "$backup" || true
  log "â¬‡ï¸  Hole aktuelle Remote-Datenâ€¦"
  git fetch origin
  log "ğŸ”„ Versuche Rebase (lokal bevorzugt)â€¦"
  if git pull --rebase -s recursive -X ours origin "$branch"; then
    log "âœ… Rebase erfolgreich"; return
  fi
  log "âš ï¸ Rebase gescheitert â€“ versuche Merge (ours bevorzugt)â€¦"
  if git merge -s recursive -X ours origin/"$branch"; then
    log "âœ… Merge erfolgreich"; return
  fi
  log "âŒ Automatisches Heilen fehlgeschlagen. Bitte manuell lÃ¶sen."
  exit 1
}

cmd_reload(){
  echo "ğŸ”„ Shell wird neu gestartet..."
  echo "WÃ¤hle Ziel:"
  echo "  1) Termux (Standard)"
  echo "  2) Debian-Proot (fÃ¼r Bun)"
  read -p "â¤ Eingabe [1/2]: " choice
  case "$choice" in
    2) echo "ğŸš€ Starte Debian-Shell..."; exec proot-distro login debian -- bash -l ;;
    *) echo "ğŸš€ Starte Termux-Shell neu..."; exec bash -l ;;
  esac
}

usage(){
  cat <<USAGE
âš¡ wg usage:
  wg go       - schnelle Checks/Startprobe
  wg doctor   - Umgebung prÃ¼fen (git, curl, bun)
  wg send     - add/commit (Auto-Msg) + push
  wg sync     - fetch + pull --rebase (ours)
  wg heal     - Konflikte heilen (Backup â†’ rebase -X ours â†’ merge -X ours)
  wg reload   - Shell neu starten (Termux/Proot)
USAGE
}

case "$1" in
  go)      cmd_go ;;
  doctor)  cmd_doctor ;;
  send)    cmd_send ;;
  sync)    cmd_sync ;;
  heal)    cmd_heal ;;
  reload)  cmd_reload ;;
  ""|help|-h|--help) usage ;;
  *) echo "Unbekannt: $1"; usage; exit 1 ;;
esac
```

### ğŸ“„ wg.bak.1757191907

**GrÃ¶ÃŸe:** 3.06 KB

```
#!/data/data/com.termux/files/usr/bin/bash
# Weltgewebe CLI (Termux) â€“ interaktiv; KEIN set -e/-u/pipefail

repo_default="$HOME/weltgewebe-repo"
repo_detected="$(git -C "$PWD" rev-parse --show-toplevel 2>/dev/null)"
repo="${repo_detected:-$repo_default}"

log(){ printf "%s\n" "$*"; }
ensure_repo(){ [ -d "$repo/.git" ] || { log "âŒ Repo nicht gefunden: $repo"; exit 1; }; }

cmd_go(){
  ensure_repo
  log "ğŸŒ Starte Weltgewebe-Checksâ€¦"
  ( cd "$repo" && ls -1 .codex scripts scripts/k6 scripts/lighthouse 2>/dev/null )
  if [ -x "$HOME/debian-bun" ]; then
    log "â¡ï¸  Bun (Proot): $(~/debian-bun 2>/dev/null)"
  else
    log "â„¹ï¸  Bun (Proot) nicht eingerichtet â€“ nur Dateichecks."
  fi
}

cmd_doctor(){
  ensure_repo
  log "ğŸ©º Doctor:"
  command -v git >/dev/null && log "âœ… git: $(git --version)" || log "âŒ git fehlt"
  command -v curl >/dev/null && log "âœ… curl: $(curl --version | head -n1)" || log "âŒ curl fehlt"
  if [ -x "$HOME/debian-bun" ]; then log "âœ… bun (proot): $(~/debian-bun)"; else log "âš ï¸ bun nicht aktiv (ok)"; fi
  ( cd "$repo" && log "ğŸ“œ letzte Commits:" && git --no-pager log --oneline -n 5 )
}

cmd_send(){
  ensure_repo
  cd "$repo" || exit 1
  branch="$(git rev-parse --abbrev-ref HEAD 2>/dev/null || echo main)"
  ts="$(date -u "+%Y-%m-%d %H:%M:%S UTC")"
  host="$(termux-info 2>/dev/null | awk -F": " "/Device model/{print \$2}" | head -n1)"
  msg="wg: mobile push $ts${host:+ [$host]}"
  git add -A
  if git diff --staged --quiet; then
    log "â„¹ï¸  Keine Ã„nderungen zum Commit. Pushe nur."
  else
    git commit -m "$msg" || { log "âŒ Commit fehlgeschlagen"; exit 1; }
  fi
  git push origin "$branch" || { log "âŒ Push fehlgeschlagen"; exit 1; }
  log "âœ… Gesendet auf $branch"
}

cmd_sync(){
  ensure_repo
  cd "$repo" || exit 1
  git fetch origin
  git pull --rebase -s recursive -X ours origin "$(git rev-parse --abbrev-ref HEAD)"
}

cmd_reload(){
  # Nutzung: wg reload [1|2]
  local choice="$1"
  local repo_abs; repo_abs="$(cd "$repo" 2>/dev/null && pwd || echo "$repo")"

  if [ -z "$choice" ]; then
    echo "ğŸ”„ Shell wird neu gestartetâ€¦"
    echo "  1) Termux (Standard)"
    echo "  2) Debian-Proot (fÃ¼r Bun; startet im Repo)"
    read -p "â¤ Eingabe [1/2]: " choice
  fi

  case "$choice" in
    2)
      echo "ğŸš€ Starte Debian-Shell (im Repo): $repo_abs"
      exec proot-distro login debian -- bash -lc "cd \"$repo_abs\" 2>/dev/null || cd ~; exec bash -l"
      ;;
    *)
      echo "ğŸš€ Starte Termux-Shell neuâ€¦"
      exec bash -l
      ;;
  esac
}

usage(){
  cat <<USAGE
âš¡ wg usage:
  wg go        â€“ schnelle Checks/Startprobe
  wg doctor    â€“ Umgebung prÃ¼fen (git, curl, bun)
  wg send      â€“ add/commit (auto-msg) + push
  wg sync      â€“ fetch + pull --rebase (lokal bevorzugt)
  wg reload [1|2] â€“ 1: Termux, 2: Debian-Proot IM REPO
USAGE
}

case "$1" in
  go)       shift; cmd_go "$@" ;;
  doctor)   shift; cmd_doctor "$@" ;;
  send)     shift; cmd_send "$@" ;;
  sync)     shift; cmd_sync "$@" ;;
  reload)   shift; cmd_reload "$1" ;;
  ""|help|-h|--help) usage ;;
  *) echo "Unbekannt: $1"; usage; exit 1 ;;
esac
```

### ğŸ“„ wg.bak.1757192266

**GrÃ¶ÃŸe:** 1.38 KB

```
#!/usr/bin/env bash
# Weltgewebe CLI â€“ interaktiv; KEIN set -e/-u/pipefail (Termux-tolerant)

repo_default="$(cd "$(dirname "$0")" && pwd)"
repo_detected="$(git -C "$PWD" rev-parse --show-toplevel 2>/dev/null)"
repo="${repo_detected:-$repo_default}"

is_termux=0; case "$PREFIX" in
  */com.termux/*) is_termux=1 ;;
esac

log(){ printf "%s\n" "$*"; }
ensure_repo(){ [ -d "$repo/.git" ] || { log "âŒ Repo nicht gefunden: $repo"; exit 1; }; }

cmd_go(){
  ensure_repo
  log "ğŸŒ Startchecksâ€¦"
  ( cd "$repo" && ls -1 .codex scripts 2>/dev/null || true )
  if [ "$is_termux" -eq 1 ] && [ -x "$HOME/debian-bun" ]; then
    log "â¡ï¸  Bun (Proot): $(~/debian-bun 2>/dev/null)"
  else
    log "â„¹ï¸  Bun-Proot optional; auf Codespaces/PC nicht nÃ¶tig."
  fi
}

cmd_doctor(){
  ensure_repo
  log "ğŸ©º Doctor:"
  command -v git >/dev/null && log "âœ… git: $(git --version)" || log "âŒ git fehlt"
  command -v curl >/dev/null && log "âœ… curl: $(curl --version | head -n1)" || log "âŒ curl fehlt"
  if [ "$is_termux" -eq 1 ] && [ -x "$HOME/debian-bun" ]; then log "âœ… bun (proot): $(~/debian-bun)"; fi
  ( cd "$repo" && log "ğŸ“œ letzte Commits:" && git --no-pager log --oneline -n 5 || true )
}

cmd_send(){
  ensure_repo; cd "$repo" || exit 1
  branch="$(git rev-parse --abbrev-ref HEAD 2>/dev/null || echo main)"
  ts="$(date -u "+%Y-%m-%d %H:%M:%S UTC")"
  host="$( (termux-info 2>/dev/null | awk -F:
```

### ğŸ“„ wg.bak.1757192687

**GrÃ¶ÃŸe:** 2.11 KB

```
#!/usr/bin/env bash
# wg â€“ Weltgewebe CLI (portabel). Kein set -e/-u/pipefail (Termux-tolerant)

repo_default="$(cd "$(dirname "$0")" && pwd)"
repo_detected="$(git -C "$PWD" rev-parse --show-toplevel 2>/dev/null)"
repo="${repo_detected:-$repo_default}"

is_termux=0; case "$PREFIX" in */com.termux/*) is_termux=1 ;; esac

log(){ printf "%s\n" "$*"; }
ensure_repo(){ [ -d "$repo/.git" ] || { log "âŒ Repo nicht gefunden: $repo"; exit 1; }; }

cmd_go(){ ensure_repo; log "ğŸŒ Startchecksâ€¦"; (cd "$repo" && ls -1 .codex scripts 2>/dev/null || true); }
cmd_doctor(){ ensure_repo; log "ğŸ©º Doctor:"; command -v git >/dev/null && git --version || log "âŒ git fehlt"; }
cmd_send(){ ensure_repo; cd "$repo" || exit 1;
  branch="$(git rev-parse --abbrev-ref HEAD 2>/dev/null || echo main)"
  ts="$(date -u "+%Y-%m-%d %H:%M:%S UTC")"
  host="$(hostname 2>/dev/null || true)"; msg="wg: push $ts${host:+ [$host]}"
  git add -A; git diff --staged --quiet || git commit -m "$msg"; git push origin "$branch"; log "âœ… Gesendet auf $branch"; }
cmd_sync(){ ensure_repo; cd "$repo" || exit 1; git fetch origin; git pull --rebase -s recursive -X ours origin "$(git rev-parse --abbrev-ref HEAD)"; }
cmd_reload(){ # wg reload [1|2]
  local choice="$1" repo_abs; repo_abs="$(cd "$repo" 2>/dev/null && pwd || echo "$repo")"
  if [ -z "$choice" ]; then
    echo "ğŸ”„ Shell neuâ€¦"; echo "  1) Shell neu starten"; [ "$is_termux" -eq 1 ] && echo "  2) Debian-Proot (im Repo)"
    read -p "â¤ Eingabe [1$([ "$is_termux" -eq 1 ] && echo "/2")]: " choice
  fi
  case "$choice" in
    2) if [ "$is_termux" -eq 1 ]; then echo "ğŸš€ Debian-Proot im Repo: $repo_abs"; exec proot-distro login debian -- bash -lc "cd \"$repo_abs\" || cd ~; exec bash -l"; else exec bash -l; fi ;;
    *) echo "ğŸš€ Starte Shell neuâ€¦"; exec bash -l ;;
  esac
}

usage(){ cat <<USAGE
âš¡ wg usage:
  wg go | doctor | send | sync | reload [1|2]
USAGE
}

case "$1" in
  go) shift; cmd_go "$@";;
  doctor) shift; cmd_doctor "$@";;
  send) shift; cmd_send "$@";;
  sync) shift; cmd_sync "$@";;
  reload) shift; cmd_reload "$1";;
  ""|help|-h|--help) usage;;
  *) echo "Unbekannt: $1"; usage; exit 1;;
esac
```

